- Straton, N., Mukkamala, R. R. and Vatrapu, R. (2015) 'Big Social Data Analytics for Public Health : Predicting Facebook Post Performance using Artificial Neural Networks and Deep Learning'.
@INPROCEEDINGS{8029313,
  author={Straton, Nadiya and Mukkamala, Raghava Rao and Vatrapu, Ravi},
  booktitle={2017 IEEE International Congress on Big Data (BigData Congress)}, 
  title={Big Social Data Analytics for Public Health: Predicting Facebook Post Performance Using Artificial Neural Networks and Deep Learning}, 
  year={2017},
  volume={},
  number={},
  pages={89-96},
  doi={10.1109/BigDataCongress.2017.21}}

- Ohsawa, S. and Matsuo, Y. (2013) 'Like Prediction: Modeling Like Counts by Bridging Facebook Pages with Linked Data', \textit{Proceedings of the 22Nd International Conference on World Wide Web Companion}, pp. 541–548. doi: 10.1145/2487788.2487992.
@article{Ohsawa2013,
abstract = {Recent growth of social media has produced a new market for branding of people and businesses. Facebook provides Facebook Pages (Pages in short) for public figures and businesses (we call entities) to communicate with their fans through a Like button. Because Like counts sometimes reflect the popularity of entities, techniques to increase the Like count can be a matter of interest, and might be known as social media marketing. From an academic perspective, Like counts of Pages depend not only on the popularity of the entity, but also on the popularity of semantically related entities. For example, Lady Gaga's Page has many Likes; her song "Poker Face" does too. We can infer that her next song will acquire many Likes immediately. Important questions are these: How does the Like count of Lady Gaga affect the Like count of her song? Alternatively, how does the Like count of her song constitute some fraction of the Like count of Lady Gaga herself? As described in this paper, we strive to reveal the mutual influences of Like counts among semantically related entities. To measure the influence of related entities, we propose a problem called the Like prediction problem (LPP). It models Like counts of a given entity using information of related entities. The semantic relations among entities, expressed as RDF predicates, are obtained by linking each Page with the most similar DBpedia entity. Using the model learned by support vector regression (SVR) on LPP, we can estimate the Like count of a new entity e.g., Lady Gaga's new song. More importantly, we can analyze which RDF predicates are important to infer Like counts, providing a mutual influence network among entities. Our study comprises three parts: (1) crawling the Pages and their Like counts, (2) linking Pages to DBpedia, and (3) constructing features to solve the LPP. Our study, based on 20 million Pages with 30 billion Likes, is the largest-scale study of Facebook Likes ever reported. This research constitutes a new attempt to integrate unstructured emotional data such as Likes, with Linked data, and to provide new insights for branding with social media.},
author = {Ohsawa, Shohei and Matsuo, Yutaka},
doi = {10.1145/2487788.2487992},
isbn = {978-1-4503-2038-2},
journal = {Proceedings of the 22Nd International Conference on World Wide Web Companion},
keywords = {entity linking,facebook,feature construction,link-based prediction,linked data},
pages = {541--548},
title = {{Like Prediction: Modeling Like Counts by Bridging Facebook Pages with Linked Data}},
url = {http://dl.acm.org/citation.cfm?id=2487788.2487992},
year = {2013}
}


- Li, C. et al. (2015) 'Click-through Prediction for Advertising in Twitter Timeline', \textit{Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining} - KDD '15, pp. 1959–1968. doi: 10.1145/2783258.2788582.
@article{Li2015,
abstract = {We present the problem of click-through prediction for advertis-ing in Twitter timeline, which displays a stream of Tweets from accounts a user choose to follow. Traditional computational adver-tising usually appears in two forms: sponsored search that places ads onto the search result page when a query is issued to a search engine, and contextual advertising that places ads onto a regular, usually static Web page. Compared with these two paradigms, placing ads into a Tweet stream is particularly challenging given the nature of the data stream: the context into which an ad can be placed updates dynamically and never replicates. Every ad is therefore placed into a unique context. This makes the information available for training a machine learning model extremely sparse. In this study, we propose a learning-to-rank method which not only addresses the sparsity of training signals but also can be trained and updated online. The proposed method is evaluated using both offline experiments and online A/B tests, which involve very large collections of Twitter data and real Twitter users. Results of the experiments prove the effectiveness and efficiency of our solution, and its superiority over the current production model adopted by Twitter.},
author = {Li, Cheng and Lu, Yue and Mei, Qiaozhu and Wang, Dong and Pandey, Sandeep},
doi = {10.1145/2783258.2788582},
isbn = {9781450336642},
journal = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD '15},
keywords = {click-through predic-,online advertising,social media stream},
pages = {1959--1968},
title = {{Click-through Prediction for Advertising in Twitter Timeline}},
url = {http://dl.acm.org/citation.cfm?doid=2783258.2788582},
year = {2015}
}

- Wang, Y. et al. (2015) 'Unsupervised sentiment analysis for social media images', \textit{Proceedings of the 24th International Conference on Artificial Intelligence}, pp. 2378–2379. Available at: \url{https://arxiv.org/abs/1604.03489}.
Wang_et_al_2015
@article{Wang2015,
abstract = {Recently text-based sentiment prediction has been extensively studied, while image-centric sentiment analysis receives much less attention. In this pa-per, we study the problem of understanding human sentiments from large-scale social media images, considering both visual content and contextual in-formation, such as comments on the images, cap-tions, etc. The challenge of this problem lies in the " semantic gap " between low-level visual fea-tures and higher-level image sentiments. Moreover, the lack of proper annotations/labels in the major-ity of social media images presents another chal-lenge. To address these two challenges, we propose a novel Unsupervised SEntiment Analysis (USEA) framework for social media images. Our approach exploits relations among visual content and rele-vant contextual information to bridge the " semantic gap " in the prediction of image sentiments. With experiments on two large-scale datasets, we show that the proposed method is effective in addressing the two challenges.},
author = {Wang, Yilin and Wang, Suhang and Tang, Jiliang and Liu, Huan and Li, Baoxin},
isbn = {9781577357384},
journal = {Proceedings of the 24th International Conference on Artificial Intelligence},
pages = {2378--2379},
title = {{Unsupervised sentiment analysis for social media images}},
url = {https://arxiv.org/abs/1604.03489},
year = {2015}
}

- Liu, B. (2012) 'Sentiment Analysis and Opinion Mining', (May), pp. 1–108. \newline doi: 10.2200/S00416ED1V01Y201204HLT016.

@article{Liu2012,
abstract = {http://www.morganclaypool.com/doi/abs/10.2200/S00416ED1V01Y201204HLT016},
archivePrefix = {arXiv},
arxivId = {1003.5699},
author = {Liu, Bing},
doi = {10.2200/S00416ED1V01Y201204HLT016},
eprint = {1003.5699},
isbn = {9781608458844},
issn = {1947-4040},
number = {May},
pages = {1--108},
pmid = {791643259},
title = {{Sentiment Analysis and Opinion Mining}},
year = {2012}
}
  

- Chen, T. et al. (2014) 'DeepSentiBank: Visual Sentiment Concept Classification with Deep Convolutional Neural Networks'. Available at: \url{http://arxiv.org/abs/1410.8586}.

@article{Chen2014,
abstract = {This paper introduces a visual sentiment concept classification method based on deep convolutional neural networks (CNNs). The visual sentiment concepts are adjective noun pairs (ANPs) automatically discovered from the tags of web photos, and can be utilized as effective statistical cues for detecting emotions depicted in the images. Nearly one million Flickr images tagged with these ANPs are downloaded to train the classifiers of the concepts. We adopt the popular model of deep convolutional neural networks which recently shows great performance improvement on classifying large-scale web-based image dataset such as ImageNet. Our deep CNNs model is trained based on Caffe, a newly developed deep learning framework. To deal with the biased training data which only contains images with strong sentiment and to prevent overfitting, we initialize the model with the model weights trained from ImageNet. Performance evaluation shows the newly trained deep CNNs model SentiBank 2.0 (or called DeepSentiBank) is significantly improved in both annotation accuracy and retrieval performance, compared to its predecessors which mainly use binary SVM classification models.},
archivePrefix = {arXiv},
arxivId = {1410.8586},
author = {Chen, Tao and Borth, Damian and Darrell, Trevor and Chang, Shih-Fu},
eprint = {1410.8586},
file = {:Users/ccrowe/Library/Application Support/Mendeley Desktop/Downloaded/Chen et al. - 2014 - DeepSentiBank Visual Sentiment Concept Classification with Deep Convolutional Neural Networks.pdf:pdf},
isbn = {9781509040452},
keywords = {affective computing,deep learning,visual sentiment},
title = {{DeepSentiBank: Visual Sentiment Concept Classification with Deep Convolutional Neural Networks}},
url = {http://arxiv.org/abs/1410.8586},
year = {2014}
}
    
- Poria, S. et al. (2016) 'A Deeper Look into Sarcastic Tweets Using Deep Convolutional Neural Networks'. Available at: \url{http://arxiv.org/abs/1610.08815}.

@article{Poria2016,
abstract = {Sarcasm detection is a key task for many natural language processing tasks. In sentiment analysis, for example, sarcasm can flip the polarity of an "apparently positive" sentence and, hence, negatively affect polarity detection performance. To date, most approaches to sarcasm detection have treated the task primarily as a text categorization problem. Sarcasm, however, can be expressed in very subtle ways and requires a deeper understanding of natural language that standard text categorization techniques cannot grasp. In this work, we develop models based on a pre-trained convolutional neural network for extracting sentiment, emotion and personality features for sarcasm detection. Such features, along with the network's baseline features, allow the proposed models to outperform the state of the art on benchmark datasets. We also address the often ignored generalizability issue of classifying data that have not been seen by the models at learning phase.},
archivePrefix = {arXiv},
arxivId = {1610.08815},
author = {Poria, Soujanya and Cambria, Erik and Hazarika, Devamanyu and Vij, Prateek},
eprint = {1610.08815},
file = {:Users/ccrowe/Library/Application Support/Mendeley Desktop/Downloaded/Poria et al. - 2016 - A Deeper Look into Sarcastic Tweets Using Deep Convolutional Neural Networks.pdf:pdf},
title = {{A Deeper Look into Sarcastic Tweets Using Deep Convolutional Neural Networks}},
url = {http://arxiv.org/abs/1610.08815},
year = {2016}
}
    
- Segalin, C., Cheng, D. S. and Cristani, M. (2017) 'Social profiling through image understanding: Personality inference using convolutional neural networks', Computer Vision and Image Understanding. Academic Press, 156, pp. 34–50. doi: 10.1016/J.CVIU.2016.10.013.
@article{Segalin2017,
abstract = {The role of images in the last ten years has changed radically due to the advent of social networks: from media objects mainly used to communicate visual information, images have become personal, associated with the people that create or interact with them (for example, giving a “like”). Therefore, in the same way that a post reveals something of its author, so now the images associated to a person may embed some of her individual characteristics, such as her personality traits. In this paper, we explore this new level of image understanding with the ultimate goal of relating a set of image preferences to personality traits by using a deep learning framework. In particular, our problem focuses on inferring both self-assessed (how the personality traits of a person can be guessed from her preferred image) and attributed traits (what impressions in terms of personality traits these images trigger in unacquainted people), learning a sort of wisdom of the crowds. Our characterization of each image is locked within the layers of a CNN, allowing us to discover more entangled attributes (aesthetic patterns and semantic information) and to better generalize the patterns that identify a trait. The experimental results show that the proposed method outperforms state-of-the-art results and captures what visually characterizes a certain trait: using a deconvolution strategy we found a clear distinction of features, patterns and content between low and high values in a given trait.},
author = {Segalin, Cristina and Cheng, Dong Seon and Cristani, Marco},
doi = {10.1016/J.CVIU.2016.10.013},
issn = {1077-3142},
journal = {Computer Vision and Image Understanding},
month = {mar},
pages = {34--50},
publisher = {Academic Press},
title = {{Social profiling through image understanding: Personality inference using convolutional neural networks}},
url = {https://www.sciencedirect.com/science/article/pii/S1077314216301679},
volume = {156},
year = {2017}
}


- Gelli, F. et al. (2015) 'Image Popularity Prediction in Social Media Using Sentiment and Context Features', \textit{Proceedings of the 23rd ACM international conference on Multimedia} - MM '15, pp. 907–910. doi: 10.1145/2733373.2806361.
@article{Gelli2015,
abstract = {{\textcopyright} 2015 ACM.Images in social networks share difierent destinies: some are going to become popular while others are going to be com-pletely unnoticed. In this paper we propose to use visual sentiment features together with three novel context fea-tures to predict a concise popularity score of social images. Experiments on large scale datasets show the benefits of proposed features on the performance of image popularity prediction. Exploiting state-of-The-Art sentiment features, we report a qualitative analysis of which sentiments seem to be related to good or poor popularity. To the best of our knowledge, this is the first work understanding specific visual sentiments that positively or negatively inuence the eventual popularity of images.},
author = {Gelli, Francesco and Uricchio, Tiberio and Bertini, Marco and {Del Bimbo}, Alberto and Chang, Shih-Fu},
doi = {10.1145/2733373.2806361},
file = {:Users/ccrowe/Library/Application Support/Mendeley Desktop/Downloaded/Gelli et al. - 2015 - Image Popularity Prediction in Social Media Using Sentiment and Context Features.pdf:pdf},
isbn = {9781450334594},
journal = {Proceedings of the 23rd ACM international conference on Multimedia - MM '15},
keywords = {affec-,image popularity,social networks,visual sentiment},
pages = {907--910},
title = {{Image Popularity Prediction in Social Media Using Sentiment and Context Features}},
url = {http://dl.acm.org/citation.cfm?doid=2733373.2806361},
year = {2015}
}
  
- Hassner, G. L. and T. (2015) 'Age and Gender Classification using Convolutional Neural Networks', \textit{2008 8th IEEE International Conference on Automatic Face and Gesture Recognition}, FG 2008, 24(3), pp. 2622–2629. doi: 10.1109/AFGR.2008.4813314.
@article{Hassner2015,
abstract = {A key point in automatic age estimation is to design feature set essential to age perception. To achieve this goal, this paper builds up a hierarchical graphical face model for faces appearing at low, middle and high resolution respectively. Along the hierarchy, a face image is decomposed into detailed parts from coarse to fine. Then four types of features are extracted from this graph representation guided by the priors of aging process embedded in the graphical model: topology, geometry, photometry and configuration. On age estimation, this paper follows the popular regression formulation for mapping feature vectors to its age label. The effectiveness of the presented feature set is justified by testing results on two datasets using different kinds of regression methods. The experimental results in this paper show that designing feature set for age estimation under the guidance of hierarchical face model is a promising method and a flexible framework as well.},
author = {Hassner, Gil Levi and Tal},
doi = {10.1109/AFGR.2008.4813314},
file = {:Users/ccrowe/Library/Application Support/Mendeley Desktop/Downloaded/Hassner - 2015 - Age and Gender Classification using Convolutional Neural Networks.pdf:pdf},
isbn = {9781424421541},
issn = {01628828},
journal = {2008 8th IEEE International Conference on Automatic Face and Gesture Recognition, FG 2008},
keywords = {Age estimation,Age manifold,Aging,Aging variation,Algorithms,Artificial Intelligence,Automated,Automated: methods,Biological,Biometry,Biometry: methods,Computer Simulation,Computer vision,Computer-Assisted,Computer-Assisted: methods,Conformal embedding analysis,Crowd density estimation,Cumulative attributes,Dimensionality reduction,Distance metric learning,Face,Face aging,Face and gesture recognition,Face recognition,Face: anatomy & histology,Human age estimation,Humans,Image Enhancement,Image Enhancement: methods,Image Interpretation,Image classification,Local regression,Locally adjusted robust regression,Machine learning,Manifold,Manifold learning,Models,Multiple linear regression,Neural networks,Nonlinear regression,Ordinal ranking,Pattern Recognition,Pattern recognition,Reproducibility of Results,Sensitivity and Specificity,Statistical face models,Subspace learning,Support vector machine (SVM),Support vector regression (SVR),active appearance model,age estimation,age progression,age specific human-computer interaction,age synthesis,aging pattern,all or part of,automatic age,binary classification,estimation,face image,face recognition,facial image processing,human age estimation,label distribution,machine learning,or hard copies of,permission to make digital,ranking,scattering transform,survey,this work for},
number = {3},
pages = {2622--2629},
pmid = {25576566},
title = {{Age and Gender Classification using Convolutional Neural Networks}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4761364%5Cnhttp://portal.acm.org/citation.cfm?doid=1180639.1180711%5Cnhttp://www.ncbi.nlm.nih.gov/pubmed/21193381%5Cnhttp://dx.doi.org/10.1016/j.patcog.2012.09.011},
volume = {24},
year = {2015}
}
  
- Tiago, M. T. P. M. B. and Veríssimo, J. M. C. (2014) 'Digital marketing and social media: Why bother?', Business Horizons, 57(6), pp. 703–708. doi: 10.1016/j.bushor.2014.07.002.
@article{TIAGO2014703,
title = {Digital marketing and social media: Why bother?},
journal = {Business Horizons},
volume = {57},
number = {6},
pages = {703-708},
year = {2014},
note = {SPECIAL ISSUE: INBAM},
issn = {0007-6813},
doi = {https://doi.org/10.1016/j.bushor.2014.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S0007681314000949},
author = {Maria Teresa Pinheiro Melo Borges Tiago and José Manuel Cristóvão Veríssimo},
keywords = {Digital marketing, Budget spending, Social metrics, Digital media trends},
abstract = {Changes in consumer behavior require firms to rethink their marketing strategies in the digital domain. Currently, a significant portion of the associated research is focused more on the customer than on the firm. To redress this shortcoming, this study adopts the perspective of the firm to facilitate an understanding of digital marketing and social media usage as well as its benefits and inhibitors. The second generation of Internet-based applications enhances marketing efforts by allowing firms to implement innovative forms of communication and co-create content with their customers. Based on a survey of marketing managers, this article shows that firms face internal and external pressures to adopt a digital presence in social media platforms. Firms’ digital marketing engagement can be categorized according to perceived benefits and digital marketing usage. To improve digital marketing engagement, marketers must focus on relationship-based interactions with their customers. This article demonstrates how some firms are already accomplishing just that.}
}  
- Fisher, T. (2009) 'ROI in social media: A look at the arguments', \textit{Journal of Database Marketing and Customer Strategy Management}, 16(3), pp. 189–195.\newline doi: 10.1057/dbm.2009.16.
@article{Fisher2009,
abstract = {Return on Investment (ROI) has become the Holy Grail of social media. Marketers are being squeezed between admonishments to participate in the vast new online communications available to them and demands to justify the cost using conventional advertising metrics. New ROI calculators are being created almost as fast as new social networking sites- then just as quickly being dismissed as being unworkable. In this article, Tia Fisher of eModeration takes a long view of the current state of ROI in social media, and examines the arguments for and against attempting to use any kind of metric to justify involvement in a social media program. {\textcopyright} 2009 Palgrave Macmillan.},
author = {Fisher, Tia},
doi = {10.1057/dbm.2009.16},
file = {:Users/ccrowe/Library/Application Support/Mendeley Desktop/Downloaded/Fisher - 2009 - ROI in social media A look at the arguments.pdf:pdf},
issn = {17412439},
journal = {Journal of Database Marketing and Customer Strategy Management},
keywords = {Marketing,Marketing budgets,ROI,Social media},
number = {3},
pages = {189--195},
title = {{ROI in social media: A look at the arguments}},
volume = {16},
year = {2009}
}
  
- Romero Nuria' (2011), 24, pp. 145–151. doi: 10.1108/08880451111169223.
@article{Romero2011,
abstract = {Purpose: In all projections for 2011, ROI has become of the great challenges of social media marketing for the business environment. However in the case of non-profit organizations, there is no need for such calculations. It is not as necessary to know how the effort made in these media compares to the benefits that can be obtained. This paper aims to compare the parameters governing social media ROI at an enterprise level and at the level of non-profit institutions. Additionally, the use of social media tools in a strategic plan and to save costs in the institution is discussed. Design/methodology/approach: Where ROI is defined as a mere indicator of return on investment, it involves the direct costs and revenues of each transaction. Combining the world of social media marketing, which is full of intangibles, with the current crisis makes knowing "real" return one of the greatest current needs. When demanding returns from institutions that have never been analyzed from this standpoint, it is important to understand how a tool like this can be used to justify an entity's visibility, brand improvement and ultimately, an increase in the institution's quality and use by users. Also, it should be taken into account that while in 2010 branding was the primary goal of communication in social media, this year in view of the increasingly endemic crisis, a ROI analysis can help an institution to evidence how the cost savings inherent in using these as opposed to former marketing tools substantiate their use. However, this interest involves a great risk of simplification. Findings: The analysis used to measure ROI can follow these lines: The consumption by previous users can be compared with that of current arrivals on the network. Comparisons can be made between the behavior of a user prior to following the library on social media and after doing so. The extent to which the success of new developments, events etc. has improved after being communicated in social networks can be measured. The influence of brand perception on users' consumption and the extent to which the new media have changed this perception can be measured. Originality/value: Conducting a ROI analysis of a library's social media marketing campaign can help it evaluate various aspects in the library. Social media can be considered as an interesting information dissemination tool requiring only minimal effort which can be used by the library to promote reading and publicize its informational and cultural efforts. Social media can also be used as dynamic, provision of service and marketing resources with a clear reduction in costs compared to other more traditional types of advertising and publicizing. Given that in the management of these tools, it is the contents and ideas that are essential rather than the economic resources available, social media are particularly useful for small and medium libraries as they provide the possibility of increasing the visibility of the institution and improving its service and its users' experience. Opening a new channel of communication with users on the internet is a challenge for libraries that can be optimized with the development of a strategy for the use of social media. The library should make an effort to manage these resources efficiently and obtain the largest possible return on their use. {\textcopyright} Emerald Group Publishing Limited.},
author = {Romero, Nuria Lloret},
doi = {10.1108/08880451111169223},
issn = {0888045X},
journal = {Bottom Line},
number = {2},
title = {{ROI. Measuring the social media return on investment in a library}},
volume = {24},
year = {2011}
}
  
- Schacht, J., Hall, M. and Chorley, M. (2015) 'Tweet if you will – the real question is , who do you influence?', (June). doi: 10.1145/2786451.2786923.
@article{Schacht2015,
abstract = {Large numbers of today's businesses use social media in advertising. There is a belief in a great opportunity, even if return on investment is difficult to quantify. To fill this gap we consider a cross-media-platform-analysis across Facebook, Twitter and Foursquare. Rationale for and against different characteristics within social media advertisement are addressed. The paper finds correlation from posts and tweets to Foursquare check-ins. Results show that posts or tweets containing pictures have higher return on investment than posts or tweets without, and that when the text of a post or tweet raises curiosity or attracts individuals or groups Foursquare check-ins increase.},
author = {Schacht, Johanna and Hall, Margeret and Chorley, Martin},
doi = {10.1145/2786451.2786923},
file = {:Users/ccrowe/Library/Application Support/Mendeley Desktop/Downloaded/Schacht, Hall, Chorley - 2015 - Tweet if you will - The real question is, who do you influence.pdf:pdf},
isbn = {9781450336727},
journal = {Proceedings of the 2015 ACM Web Science Conference},
number = {June},
title = {{Tweet if you will - The real question is, who do you influence?}},
year = {2015}
}

- Wang, Y. et al. (2015) 'Unsupervised sentiment analysis for social media images', \textit{Proceedings of the 24th International Conference on Artificial Intelligence}, pp. 2378–2379. Available at: \url{https://arxiv.org/abs/1604.03489}.
@article{Wang2015,
abstract = {Recently text-based sentiment prediction has been extensively studied, while image-centric sentiment analysis receives much less attention. In this pa-per, we study the problem of understanding human sentiments from large-scale social media images, considering both visual content and contextual in-formation, such as comments on the images, cap-tions, etc. The challenge of this problem lies in the " semantic gap " between low-level visual fea-tures and higher-level image sentiments. Moreover, the lack of proper annotations/labels in the major-ity of social media images presents another chal-lenge. To address these two challenges, we propose a novel Unsupervised SEntiment Analysis (USEA) framework for social media images. Our approach exploits relations among visual content and rele-vant contextual information to bridge the " semantic gap " in the prediction of image sentiments. With experiments on two large-scale datasets, we show that the proposed method is effective in addressing the two challenges.},
author = {Wang, Yilin and Wang, Suhang and Tang, Jiliang and Liu, Huan and Li, Baoxin},
isbn = {9781577357384},
journal = {Proceedings of the 24th International Conference on Artificial Intelligence},
pages = {2378--2379},
title = {{Unsupervised sentiment analysis for social media images}},
url = {https://arxiv.org/abs/1604.03489},
year = {2015}
}
  
- Poria, S. et al. (2016) 'A Deeper Look into Sarcastic Tweets Using Deep Convolutional Neural Networks'. Available at: \url{http://arxiv.org/abs/1610.08815}.
@article{Poria2016,
abstract = {Sarcasm detection is a key task for many natural language processing tasks. In sentiment analysis, for example, sarcasm can flip the polarity of an "apparently positive" sentence and, hence, negatively affect polarity detection performance. To date, most approaches to sarcasm detection have treated the task primarily as a text categorization problem. Sarcasm, however, can be expressed in very subtle ways and requires a deeper understanding of natural language that standard text categorization techniques cannot grasp. In this work, we develop models based on a pre-trained convolutional neural network for extracting sentiment, emotion and personality features for sarcasm detection. Such features, along with the network's baseline features, allow the proposed models to outperform the state of the art on benchmark datasets. We also address the often ignored generalizability issue of classifying data that have not been seen by the models at learning phase.},
archivePrefix = {arXiv},
arxivId = {1610.08815},
author = {Poria, Soujanya and Cambria, Erik and Hazarika, Devamanyu and Vij, Prateek},
eprint = {1610.08815},
file = {:Users/ccrowe/Library/Application Support/Mendeley Desktop/Downloaded/Poria et al. - 2016 - A Deeper Look into Sarcastic Tweets Using Deep Convolutional Neural Networks.pdf:pdf},
title = {{A Deeper Look into Sarcastic Tweets Using Deep Convolutional Neural Networks}},
url = {http://arxiv.org/abs/1610.08815},
year = {2016}
}
  
- Khosla, A., Das Sarma, A. and Hamid, R. (2014) 'What Makes an Image Popular ?', \textit{Proceedings of the 23rd International Conference on World Wide Web}, pp. 867--876. doi: 10.1145/2566486.2567996.
@article{Khosla2014,
abstract = {Hundreds of thousands of photographs are uploaded to the internet every minute through various social networking and photo sharing platforms. While some images get millions of views, others are completely ignored. Even from the same users, different photographs receive different number of views. This begs the question: What makes a photograph popular? Can we predict the number of views a photograph will receive even before it is uploaded? These are some of the questions we address in this work. We investigate two key components of an image that affect its popularity, namely the image content and social context. Using a dataset of about 2.3 million images from Flickr, we demonstrate that we can reliably predict the normalized view count of images with a rank correlation of 0.81 using both image content and social cues. In this paper, we show the importance of image cues such as color, gradients, deep learning features and the set of objects present, as well as the importance of various social cues such as number of friends or number of photos uploaded that lead to high or low popularity of images.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Khosla, Aditya and {Das Sarma}, Atish and Hamid, Raffay},
doi = {10.1145/2566486.2567996},
eprint = {arXiv:1011.1669v3},
file = {:Users/ccrowe/Library/Application Support/Mendeley Desktop/Downloaded/Khosla, Das Sarma, Hamid - 2014 - What Makes an Image Popular.pdf:pdf},
isbn = {9781450327442},
issn = {9781450327442},
journal = {Proceedings of the 23rd International Conference on World Wide Web},
keywords = {deep learning,flickr,images,popularity,regression},
pages = {867----876},
pmid = {15003161},
title = {{What Makes an Image Popular ?}},
url = {http://dl.acm.org/citation.cfm?id=2567996},
year = {2014}
}
  
- Chen, T. et al. (2014) 'DeepSentiBank: Visual Sentiment Concept Classification with Deep Convolutional Neural Networks'. Available at: \url{http://arxiv.org/abs/1410.8586}.
@article{Chen2014,
abstract = {This paper introduces a visual sentiment concept classification method based on deep convolutional neural networks (CNNs). The visual sentiment concepts are adjective noun pairs (ANPs) automatically discovered from the tags of web photos, and can be utilized as effective statistical cues for detecting emotions depicted in the images. Nearly one million Flickr images tagged with these ANPs are downloaded to train the classifiers of the concepts. We adopt the popular model of deep convolutional neural networks which recently shows great performance improvement on classifying large-scale web-based image dataset such as ImageNet. Our deep CNNs model is trained based on Caffe, a newly developed deep learning framework. To deal with the biased training data which only contains images with strong sentiment and to prevent overfitting, we initialize the model with the model weights trained from ImageNet. Performance evaluation shows the newly trained deep CNNs model SentiBank 2.0 (or called DeepSentiBank) is significantly improved in both annotation accuracy and retrieval performance, compared to its predecessors which mainly use binary SVM classification models.},
archivePrefix = {arXiv},
arxivId = {1410.8586},
author = {Chen, Tao and Borth, Damian and Darrell, Trevor and Chang, Shih-Fu},
eprint = {1410.8586},
file = {:Users/ccrowe/Library/Application Support/Mendeley Desktop/Downloaded/Chen et al. - 2014 - DeepSentiBank Visual Sentiment Concept Classification with Deep Convolutional Neural Networks.pdf:pdf},
isbn = {9781509040452},
keywords = {affective computing,deep learning,visual sentiment},
title = {{DeepSentiBank: Visual Sentiment Concept Classification with Deep Convolutional Neural Networks}},
url = {http://arxiv.org/abs/1410.8586},
year = {2014}
}
  
- Segalin, C., Cheng, D. S. and Cristani, M. (2017) 'Social profiling through image understanding: Personality inference using convolutional neural networks', Computer Vision and Image Understanding. Academic Press, 156, pp. 34–50. doi: 10.1016/J.CVIU.2016.10.013.
@article{Segalin2017,
abstract = {The role of images in the last ten years has changed radically due to the advent of social networks: from media objects mainly used to communicate visual information, images have become personal, associated with the people that create or interact with them (for example, giving a “like”). Therefore, in the same way that a post reveals something of its author, so now the images associated to a person may embed some of her individual characteristics, such as her personality traits. In this paper, we explore this new level of image understanding with the ultimate goal of relating a set of image preferences to personality traits by using a deep learning framework. In particular, our problem focuses on inferring both self-assessed (how the personality traits of a person can be guessed from her preferred image) and attributed traits (what impressions in terms of personality traits these images trigger in unacquainted people), learning a sort of wisdom of the crowds. Our characterization of each image is locked within the layers of a CNN, allowing us to discover more entangled attributes (aesthetic patterns and semantic information) and to better generalize the patterns that identify a trait. The experimental results show that the proposed method outperforms state-of-the-art results and captures what visually characterizes a certain trait: using a deconvolution strategy we found a clear distinction of features, patterns and content between low and high values in a given trait.},
author = {Segalin, Cristina and Cheng, Dong Seon and Cristani, Marco},
doi = {10.1016/J.CVIU.2016.10.013},
issn = {1077-3142},
journal = {Computer Vision and Image Understanding},
month = {mar},
pages = {34--50},
publisher = {Academic Press},
title = {{Social profiling through image understanding: Personality inference using convolutional neural networks}},
url = {https://www.sciencedirect.com/science/article/pii/S1077314216301679},
volume = {156},
year = {2017}
}
  
- Lin, H. et al. (2014) 'User-level psychological stress detection from social media using deep neural network', \textit{Proceedings of the ACM International Conference on Multimedia} - MM '14, pp. 507–516. doi: 10.1145/2647868.2654945.
@article{Lin2014,
abstract = {It is of significant importance to detect and manage stress before it turns into severe problems. However, existing stress detection methods usually rely on psychological scales or physiological devices, making the detection complicated and costly. In this paper, we explore to automatically detect individuals' psychological stress via social media. Employing real online micro-blog data, we first investigate the correlations between users' stress and their tweeting content, social engagement and behavior patterns. Then we define two types of stress-related attributes: 1) low-level content attributes from a single tweet, including text, images and social interactions; 2) user-scope statistical attributes through their weekly micro-blog postings, leveraging information of tweeting time, tweeting types and linguistic styles. To combine content attributes with statistical attributes, we further design a convolutional neural network (CNN) with cross autoencoders to generate user-scope content attributes from low-level content attributes. Finally, we propose a deep neural network (DNN) model to incorporate the two types of user-scope attributes to detect users' psychological stress. We test the trained model on four different datasets from major micro-blog platforms including Sina Weibo, Tencent Weibo and Twitter. Experimental results show that the proposed model is effective and efficient on detecting psychological stress from micro-blog data. We believe our model would be useful in developing stress detection tools for mental health agencies and individuals.},
author = {Lin, Huijie and Jia, Jia and Guo, Quan and Xue, Yuanyuan and Li, Qi and Huang, Jie and Cai, Lianhong and Feng, Ling},
doi = {10.1145/2647868.2654945},
file = {:Users/ccrowe/Library/Application Support/Mendeley Desktop/Downloaded/Lin et al. - 2014 - User-level psychological stress detection from social media using deep neural network.pdf:pdf},
isbn = {9781450330633},
journal = {Proceedings of the ACM International Conference on Multimedia - MM '14},
pages = {507--516},
title = {{User-level psychological stress detection from social media using deep neural network}},
url = {http://dl.acm.org/citation.cfm?doid=2647868.2654945},
year = {2014}
}
  
- Xu, C. et al. (2014) 'Visual Sentiment Prediction with Deep Convolutional Neural Networks'. Available at: \url{http://arxiv.org/abs/1411.5731}.
@article{Xu2014,
abstract = {Images have become one of the most popular types of media through which users convey their emotions within online social networks. Although vast amount of research is devoted to sentiment analysis of textual data, there has been very limited work that focuses on analyzing sentiment of image data. In this work, we propose a novel visual sentiment prediction framework that performs image understanding with Deep Convolutional Neural Networks (CNN). Specifically, the proposed sentiment prediction framework performs transfer learning from a CNN with millions of parameters, which is pre-trained on large-scale data for object recognition. Experiments conducted on two real-world datasets from Twitter and Tumblr demonstrate the effectiveness of the proposed visual sentiment analysis framework.},
archivePrefix = {arXiv},
arxivId = {1411.5731},
author = {Xu, Can and Cetintas, Suleyman and Lee, Kuang-Chih and Li, Li-Jia},
eprint = {1411.5731},
file = {:Users/ccrowe/Library/Application Support/Mendeley Desktop/Downloaded/Xu et al. - 2014 - Visual Sentiment Prediction with Deep Convolutional Neural Networks.pdf:pdf},
title = {{Visual Sentiment Prediction with Deep Convolutional Neural Networks}},
url = {http://arxiv.org/abs/1411.5731},
year = {2014}
}
  







  

  
