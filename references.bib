@article{Lin2012,
	title        = {Large-Scale Machine Learning at Twitter},
	author       = {Lin, Jimmy and Kolcz, Alek},
	year         = 2012,
	pages        = {793--804},
	isbn         = 9781450312479,
	file         = {:Users/ccrowe/Downloads/p793-lin.pdf:pdf},
	keywords     = {en-,logistic regression,online learning,sembles,stochastic gradient descent},
}
@article{Saunders2004,
	title        = {in Trained Distance Runners},
	author       = {
		Saunders, Philo U and Pyne, David B and Telford, Richard D and Hawley, John A
	},
	year         = 2004,
	volume       = 34,
	number       = 7,
	pages        = {465--485},
	file         = {:Users/ccrowe/Downloads/Saunders{\_}et{\_}al{\_}2004.pdf:pdf},
}
@article{Mizrahi2000,
	title        = {
		{E  ect of fatigue on leg kinematics and impact acceleration in long
		distance running}
	},
	author       = {Mizrahi, Joseph},
	year         = 2000,
	volume       = 19,
	pages        = {139--151},
	file         = {
		
		:Users/ccrowe/Downloads/Effect{\_}of{\_}fatigue{\_}on{\_}leg{\_}kinematics{\_}and.pdf:pdf
	},
	keywords     = {fatigued running,impact acceleration,knee angle,overload injury,stride rate},
}
@article{Bot2000,
	title        = {
		{The relationship between heart rate and oxygen uptake during non-steady
		state exercise}
	},
	author       = {Bot, S D M and Hollander, A P},
	year         = 2000,
	month        = {oct},
	journal      = {Ergonomics},
	publisher    = {Taylor {\&} Francis},
	volume       = 43,
	number       = 10,
	pages        = {1578--1592},
	doi          = {10.1080/001401300750004005},
	issn         = {0014-0139},
	url          = {https://doi.org/10.1080/001401300750004005},
	annote       = {doi: 10.1080/001401300750004005},
}
@article{Hodosh2013,
	title        = {
		{Framing Image Description as a Ranking Task : Data , Models and Evaluation
		Metrics}
	},
	author       = {Hodosh, Micah},
	year         = 2013,
	volume       = 47,
	pages        = {853--899},
	file         = {:Users/ccrowe/Downloads/10833-Article Text-20198-1-10-20180216.pdf:pdf},
}
@article{Srinivasan2018,
	title        = {Image Captioning - A Deep Learning Approach},
	author       = {Srinivasan, Lakshminarasimhan and Sreekanthan, Dinesh and Amutha, A L},
	year         = 2018,
	volume       = 13,
	number       = 9,
	pages        = {7239--7242},
	file         = {:Users/ccrowe/Downloads/ijaerv13n9{\_}102.pdf:pdf},
}
@article{Simon1995,
	title        = {Applications of Machine Learning and Rule Induction Pat Langley and},
	author       = {Simon, Herbert A},
	year         = 1995,
	volume       = 38,
	number       = 11,
	file         = {:Users/ccrowe/Downloads/LangleyNov95.pdf:pdf},
}
@article{Marelli2014,
	title        = {
		{A SICK cure for the evaluation of compositional distributional semantic A
		SICK cure for the evaluation of compositional distributional semantic models}
	},
	author       = {
		Marelli, M and Menini, S and Baroni, M and Bentivogli, L and Bernardi, R and
		Zamparelli, R
	},
	year         = 2014,
	number       = {May},
	file         = {:Users/ccrowe/Downloads/marelli-etal-sick-lrec2014.pdf:pdf},
	keywords     = {
		compositional distributional semantic models,data sets,semantic
		relatedness,textual entailment
	},
}
@article{Socher2013,
	title        = {
		{Recursive Deep Models for Semantic Compositionality Over a Sentiment
		Treebank}
	},
	author       = {
		Socher, Richard and Perelygin, Alex and Wu, Jean Y and Chuang, Jason and
		Manning, Christopher D and Ng, Andrew Y and Potts, Christopher
	},
	year         = 2013,
	number       = {October},
	pages        = {1631--1642},
	file         = {:Users/ccrowe/Downloads/D13-1170.pdf:pdf},
}
@article{Joulin2015,
	title        = {Bag of Tricks for Efficient Text Classification},
	author       = {Joulin, Armand},
	year         = 2015,
	archiveprefix = {arXiv},
	arxivid      = {arXiv:1607.01759v3},
	eprint       = {arXiv:1607.01759v3},
	file         = {:Users/ccrowe/Downloads/1607.01759.pdf:pdf},
}
@article{Shi1874,
	title        = {
		{Real-Time Single Image and Video Super-Resolution Using an Efficient
		Sub-Pixel Convolutional Neural Network}
	},
	author       = {
		Shi, Wenzhe and Caballero, Jose and Husz, Ferenc and Totz, Johannes and
		Aitken, Andrew P and Bishop, Rob and Rueckert, Daniel and Wang, Zehan
	},
	year         = 1874,
	pages        = {1874--1883},
	file         = {
		
		:Users/ccrowe/Downloads/Shi{\_}Real-Time{\_}Single{\_}Image{\_}CVPR{\_}2016{\_}paper.pdf:pdf
	},
}
@article{Schapire2002,
	title        = {The Boosting Approach to Machine Learning An Overview},
	author       = {Schapire, Robert E and Avenue, Park and Room, A},
	year         = 2002,
	pages        = {1--23},
	file         = {:Users/ccrowe/Downloads/10.1.1.24.5565.pdf:pdf},
}
@article{Guyon,
	title        = {An Introduction to Feature Extraction},
	author       = {Guyon, Isabelle},
	file         = {:Users/ccrowe/Downloads/10.1.1.85.1752.pdf:pdf},
}
@article{Hulth2001,
	title        = {Improved Automatic Keyword Extraction Given More Linguistic Knowledge},
	author       = {Hulth, Anette},
	year         = 2001,
	number       = 2000,
	file         = {:Users/ccrowe/Downloads/W03-1028.pdf:pdf},
	keywords     = {
		a keyword or a,as-,each defined term from,is classified either
		as,non-keyword,plied to documents for,signed,subsequently ap-,the trained
		model is,these documents,which no keywords are
	},
}
@article{Lecun2015,
	title        = {Deep learning},
	author       = {Lecun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	year         = 2015,
	doi          = {10.1038/nature14539},
	file         = {:Users/ccrowe/Downloads/DeepLearning{\_}LeCun.pdf:pdf},
}
@article{The2014,
	title        = {Deep Learning in Neural Networks : An Overview},
	author       = {The, Schmidhuber and Ai, Swiss and Dalle, Istituto and Galleria, Supsi},
	year         = 2014,
	pages        = {1--88},
	archiveprefix = {arXiv},
	arxivid      = {arXiv:1404.7828},
	eprint       = {arXiv:1404.7828},
	file         = {:Users/ccrowe/Downloads/1404.7828.pdf:pdf},
}
@article{SrivastavaBelief,
	title        = {Learning Representations for Multimodal Data with Deep Belief Nets},
	author       = {Srivastava, Nitish},
	file         = {:Users/ccrowe/Downloads/b28607cada5474bca772e1cc553b624415c9.pdf:pdf},
}
@article{Tsai2011,
	title        = {
		{Combining Image and Text Features : A Hybrid Approach to Mobile Book Spine
		Recognition}
	},
	author       = {
		Tsai, Sam S and Chen, David and Chen, Huizhong and Hsu, Cheng-hsin and Kim,
		Kyu-han and Singh, Jatinder P and Girod, Bernd
	},
	year         = 2011,
	pages        = {8--11},
	isbn         = 9781450306164,
	file         = {:Users/ccrowe/Downloads/Tsai{\_}ACM{\_}Multimedia{\_}11.pdf:pdf},
}
@article{SrivastavaBoltzmann,
	title        = {Multimodal Learning with Deep Boltzmann Machines},
	author       = {Srivastava, Nitish},
	pages        = {1--9},
	file         = {:Users/ccrowe/Downloads/multimodel.pdf:pdf},
}
@article{Ngiam2011,
	title        = {Multimodal Deep Learning},
	author       = {Ngiam, Jiquan and Ng, Andrew Y},
	year         = 2011,
	file         = {:Users/ccrowe/Downloads/multimodel3.pdf:pdf},
}
@article{Sohn,
	title        = {Improved Multimodal Deep Learning with Variation of Information},
	author       = {Sohn, Kihyuk and Lee, Honglak},
	pages        = {1--14},
	file         = {:Users/ccrowe/Downloads/multimodel4.pdf:pdf},
}
@article{Tran1927,
	title        = {Thurstonian Boltzmann Machines : Learning from Multiple Inequalities},
	author       = {Tran, Truyen},
	year         = 1927,
	file         = {:Users/ccrowe/Downloads/multimodel5.pdf:pdf},
	keywords     = {Restricted Boltzmann Machines, probit, inequalities},
}
@article{Teams2006,
	title        = {
		{Benefits and Problems With Student Teams : Suggestions for Improving Team
		Projects}
	},
	author       = {Teams, Work},
	year         = 2006,
	number       = {October},
	pages        = {11--20},
	file         = {:Users/ccrowe/Downloads/ContentServer.pdf:pdf},
	keywords     = {business education,group},
}
@article{studentTeams2006,
	title        = {Benefits and Problems With Student Teams},
	year         = 2006,
	number       = 2005,
	file         = {:Users/ccrowe/Downloads/Benefits and Problems With Student Teams.pdf:pdf},
}
@article{Srivastava2015,
	title        = {Unsupervised Learning of Video Representations using LSTMs},
	author       = {Srivastava, Nitish},
	year         = 2015,
	volume       = 37,
	file         = {:Users/ccrowe/Downloads/srivastava15.pdf:pdf},
}
@article{Michalski,
	title        = {Modeling Deep Temporal Dependencies with Recurrent “ Grammar Cells ”},
	author       = {Michalski, Vincent and Memisevic, Roland},
	pages        = {1--9},
	file         = {:Users/ccrowe/Downloads/convert/predictive2014.pdf:pdf},
}
@article{Susskind,
	title        = {
		{Modeling the joint density of two images under a variety of transformations}
	},
	author       = {
		Susskind, Joshua and Memisevic, Roland and Hinton, Geoffrey and Pollefeys,
		Marc
	},
	file         = {:Users/ccrowe/Downloads/convert/morphBM.pdf:pdf},
}
@article{Lan,
	title        = {
		{Beyond Gaussian Pyramid : Multi-skip Feature Stacking for Action
		Recognition}
	},
	author       = {
		Lan, Zhenzhong and Lin, Ming and Li, Xuanchong and Hauptmann, Alexander G and
		Raj, Bhiksha
	},
	file         = {
		
		:Users/ccrowe/Downloads/convert/Lan{\_}Beyond{\_}Gaussian{\_}Pyramid{\_}2015{\_}CVPR{\_}paper.pdf:pdf
	},
}
@article{Crowe2018,
	title        = {Initial Related Work},
	author       = {Crowe, Chad},
	year         = 2018,
	pages        = {1--4},
	file         = {:Users/ccrowe/Downloads/convert/Initial Related Work.pdf:pdf},
}
@article{Graves2014,
	title        = {Towards End-to-End Speech Recognition with Recurrent Neural Networks},
	author       = {Graves, Alex},
	year         = 2014,
	volume       = 32,
	file         = {:Users/ccrowe/Downloads/convert/graves14.pdf:pdf},
}
@article{Zaremba2013,
	title        = {arXiv : 1409 . 2329v3 [ cs . NE ] 3 Nov 2014},
	author       = {Zaremba, Wojciech and Com, Vinyals Google},
	year         = 2013,
	archiveprefix = {arXiv},
	arxivid      = {arXiv:1409.2329v3},
	eprint       = {arXiv:1409.2329v3},
	file         = {
		:Users/ccrowe/Downloads/convert/e8b33c0d49a692a6ce2c4bcb28588aeb7d97.pdf:pdf
	},
	keywords     = {
		Natural Language Processing, Recurrent Neural Networks, Language Model,
		LSTMs, Speech Recognition, Machine Translation
	},
}
@article{Donahue,
	title        = {
		{Long-term Recurrent Convolutional Networks for Visual Recognition and
		Description}
	},
	author       = {
		Donahue, Jeff and Hendricks, Lisa Anne and Guadarrama, Sergio and Rohrbach,
		Marcus and Venugopalan, Subhashini and Saenko, Kate and Darrell, Trevor and
		Austin, U T and Lowell, Umass and Berkeley, U C
	},
	file         = {
		
		:Users/ccrowe/Downloads/convert/Donahue{\_}Long-Term{\_}Recurrent{\_}Convolutional{\_}2015{\_}CVPR{\_}paper.pdf:pdf
	},
}
@article{Merri2014,
	title        = {
		{Learning Phrase Representations using RNN Encoder – Decoder for Statistical
		Machine Translation}
	},
	author       = {Merri, Bart Van and Fellow, Cifar Senior},
	year         = 2014,
	pages        = {1724--1734},
	file         = {:Users/ccrowe/Downloads/convert/D14-1179.pdf:pdf},
}
@article{Le,
	title        = {
		{Learning hierarchical invariant spatio-temporal features for action
		recognition with independent subspace analysis}
	},
	author       = {Le, Quoc V and Zou, Will Y and Yeung, Serena Y and Ng, Andrew Y},
	file         = {:Users/ccrowe/Downloads/convert/cvpr11-ActionRecognitionISA.pdf:pdf},
}
@article{Simonyan,
	title        = {Two-Stream Convolutional Networks for Action Recognition in Videos},
	author       = {Simonyan, Karen},
	pages        = {1--9},
	file         = {
		
		:Users/ccrowe/Downloads/convert/5353-two-stream-convolutional-networks-for-action-recognition-in-videos.pdf:pdf
	},
}
@article{Sutskever,
	title        = {Sequence to Sequence Learning with Neural Networks},
	author       = {Sutskever, Ilya},
	pages        = {1--9},
	file         = {
		
		:Users/ccrowe/Downloads/convert/5346-sequence-to-sequence-learning-with-neural-networks.pdf:pdf
	},
}
@article{Mobahi1996,
	title        = {Deep Learning from Temporal Coherence in Video},
	author       = {
		Mobahi, Hossein and Weston, Jason and America, N E C Labs and Way,
		Independence
	},
	year         = 1996,
	file         = {:Users/ccrowe/Downloads/convert/2009{\_}video{\_}icml.pdf:pdf},
}
@article{Srivastava2014,
	title        = {Unsupervised Learning of Video Representations using LSTMs},
	author       = {Srivastava, Nitish},
	year         = 2014,
	archiveprefix = {arXiv},
	arxivid      = {arXiv:1502.04681v3},
	eprint       = {arXiv:1502.04681v3},
	file         = {:Users/ccrowe/Downloads/convert/1502.04681.pdf:pdf},
}
@article{Enerative2014,
	title        = {V (l ) m : a b f g m n v},
	author       = {Enerative, F O R G and Of, M Odels and Ideos, N Atural V},
	year         = 2014,
	pages        = {1--15},
	archiveprefix = {arXiv},
	arxivid      = {arXiv:1412.6604v5},
	eprint       = {arXiv:1412.6604v5},
	file         = {:Users/ccrowe/Downloads/convert/1412.6604.pdf:pdf},
}
@article{Graves,
	title        = {Generating Sequences With Recurrent Neural Networks},
	author       = {Graves, Alex},
	pages        = {1--43},
	archiveprefix = {arXiv},
	arxivid      = {arXiv:1308.0850v5},
	eprint       = {arXiv:1308.0850v5},
	file         = {:Users/ccrowe/Downloads/convert/1308.0850.pdf:pdf},
}
@article{Soomro2012,
	title        = {UCF101 : A Dataset of 101 Human Actions Classes From Videos in The Wild},
	author       = {
		Soomro, Khurram and Zamir, Amir Roshan and Shah, Mubarak and Recognition,
		Action
	},
	year         = 2012,
	number       = {November},
	archiveprefix = {arXiv},
	arxivid      = {arXiv:1212.0402v1},
	eprint       = {arXiv:1212.0402v1},
	file         = {:Users/ccrowe/Downloads/convert/1212.0402.pdf:pdf},
	keywords     = {
		4000 central florida blvd,action dataset,action recognition,center for
		research in,computer vision,ucf101,ucf50,university of central florida
	},
}
@article{Ji2010,
	title        = {3D Convolutional Neural Networks for Human Action Recognition},
	author       = {Ji, Shuiwang and Yu, Kai},
	year         = 2010,
	file         = {:Users/ccrowe/Downloads/convert/10.1.1.169.4046 (1).pdf:pdf},
}
@article{Hurri2003,
	title        = {Simple-Cell-Like Receptive Fields Maximize Temporal},
	author       = {Hurri, Jarmo},
	year         = 2003,
	volume       = 691,
	number       = 3,
	pages        = {663--691},
	file         = {:Users/ccrowe/Downloads/convert/10.1.1.10.9262.pdf:pdf},
}
@article{Karpathy2015,
	title        = {
		{Large-scale Video Classification with Convolutional Neural Networks
		Presenter : Esha Uboweja Problem Classification of videos in sports datasets}
	},
	author       = {
		Karpathy, Andrej and Toderici, George and Shetty, Sanketh and Leung, Thomas
		and Sukthankar, Rahul and Fei-fei, Li
	},
	year         = 2015,
	number       = {June 2014},
	file         = {
		:Users/ccrowe/Downloads/convert/9c923e9f145d1c01a2de2afc38ec23c44253.pdf:pdf
	},
}
@article{M2015,
	title        = {D c m r n n ( -rnn)},
	author       = {M, N Eural N Etworks and Yuille, Alan},
	year         = 2015,
	volume       = 1090,
	number       = 2014,
	pages        = {1--17},
	archiveprefix = {arXiv},
	arxivid      = {arXiv:1412.6632v5},
	eprint       = {arXiv:1412.6632v5},
	file         = {:Users/ccrowe/Downloads/12.pdf:pdf},
}
@article{Sainath,
	title        = {No Title},
	author       = {Sainath, Tara N and Vinyals, Oriol and Senior, Andrew and York, New},
	pages        = {1--5},
	file         = {:Users/ccrowe/Downloads/11.pdf:pdf},
}
@article{Yin,
	title        = {
		{ABCNN: Attention-Based Convolutional Neural Network for Modeling Sentence
		Pairs ¨}
	},
	author       = {Yin, Wenpeng and Sch, Hinrich},
	archiveprefix = {arXiv},
	arxivid      = {arXiv:1512.05193v4},
	eprint       = {arXiv:1512.05193v4},
	file         = {:Users/ccrowe/Downloads/10.pdf:pdf},
}
@article{Wang2016,
	title        = {Dimensional Sentiment Analysis Using a Regional CNN-LSTM Model},
	author       = {Wang, Jin and Yu, Liang-chih and Lai, K Robert and Zhang, Xuejie},
	year         = 2016,
	pages        = {225--230},
	file         = {:Users/ccrowe/Downloads/9.pdf:pdf},
}
@article{Vosoughi2016,
	title        = {Tweet2Vec : Learning Tweet Embeddings Using},
	author       = {Vosoughi, Soroush and Roy, Deb},
	year         = 2016,
	pages        = {16--19},
	isbn         = 9781450340694,
	archiveprefix = {arXiv},
	arxivid      = {arXiv:1607.07514v1},
	eprint       = {arXiv:1607.07514v1},
	file         = {:Users/ccrowe/Downloads/8.pdf:pdf},
	keywords     = {
		cnn,convolutional neural
		networks,embedding,encoder-decoder,lstm,tweet,tweet2vec,twitter
	},
}
@article{Ghosh2016,
	title        = {Fracking Sarcasm using Neural Network},
	author       = {Ghosh, Aniruddha and Veale, Tony},
	year         = 2016,
	pages        = {161--169},
	file         = {:Users/ccrowe/Downloads/7.pdf:pdf},
}
@article{Fan2016,
	title        = {Video-Based Emotion Recognition using CNN-RNN and C3D Hybrid Networks},
	author       = {Fan, Yin and Lu, Xiangju and Li, Dian and Liu, Yuanliu},
	year         = 2016,
	number       = {November},
	doi          = {10.1145/2993148.2997632},
	file         = {:Users/ccrowe/Downloads/6.pdf:pdf},
}
@article{Understanding,
	title        = {
		{DiSAN: Directional Self-Attention Network for RNN/CNN-Free Language
		Understanding}
	},
	author       = {Understanding, R N N Cnn-free Language},
	archiveprefix = {arXiv},
	arxivid      = {arXiv:1709.04696v3},
	eprint       = {arXiv:1709.04696v3},
	file         = {:Users/ccrowe/Downloads/5.pdf:pdf},
}
@article{Wang,
	title        = {CNN-RNN : A Unified Framework for Multi-label Image Classification},
	author       = {
		Wang, Jiang and Yang, Yi and Mao, Junhua and Huang, Zhiheng and Huang, Chang
		and Xu, Wei
	},
	pages        = {2285--2294},
	file         = {:Users/ccrowe/Downloads/4.pdf:pdf},
}
@article{Baudi,
	title        = {Sentence Pair Scoring : Towards Unified Framework},
	author       = {Baudiˇ, Petr and Pichl, Jan},
	number       = {C},
	archiveprefix = {arXiv},
	arxivid      = {arXiv:1603.06127v4},
	eprint       = {arXiv:1603.06127v4},
	file         = {:Users/ccrowe/Downloads/3.pdf:pdf},
}
@article{Yin2016,
	title        = {Comparative Study of CNN and RNN for Natural Language Processing ¨ †},
	author       = {Yin, Wenpeng and Kann, Katharina and Yu, Mo},
	year         = 2016,
	archiveprefix = {arXiv},
	arxivid      = {arXiv:1702.01923v1},
	eprint       = {arXiv:1702.01923v1},
	file         = {:Users/ccrowe/Downloads/2.pdf:pdf},
}
@article{Lee2016,
	title        = {
		{Sequential Short-Text Classification with Recurrent and Convolutional Neural
		Networks}
	},
	author       = {Lee, Ji Young and Dernoncourt, Franck},
	year         = 2016,
	archiveprefix = {arXiv},
	arxivid      = {arXiv:1603.03827v1},
	eprint       = {arXiv:1603.03827v1},
	file         = {:Users/ccrowe/Downloads/1.pdf:pdf},
}
@article{Tucker2012,
	title        = {Social advertising},
	author       = {Tucker, Catherine E.},
	year         = 2012,
	journal      = {Working Paper},
	pages        = {1--31},
	doi          = {10.2139/ssrn.1975897},
	isbn         = 6431985923,
	issn         = {1556-5068},
	url          = {
		http://digital.mit.edu/research/papers/2012.02{\_}Tucker{\_}Social
		Advertising{\_}306.pdf
	},
	abstract     = {
		Study that shows that Social Advertising increases Ad Effectiveness, but not
		when it is clear to consumers that firms try to use social influence
	},
	file         = {
		:Users/ccrowe/Desktop/research/2012.02{\_}Tucker{\_}Social
		Advertising{\_}306.pdf:pdf
	},
}
@article{Mellon2017,
	title        = {
		{Twitter and Facebook are not representative of the general population:
		Political attitudes and demographics of british social media users}
	},
	author       = {Mellon, Jonathan and Prosser, Christopher},
	year         = 2017,
	journal      = {Research and Politics},
	volume       = 4,
	number       = 3,
	pages        = {1--9},
	doi          = {10.1177/2053168017720008},
	issn         = 20531680,
	abstract     = {
		A growing social science literature has used Twitter and Facebook to study
		political and social phenomena including for election forecasting and
		tracking political conversations. This research note uses a nationally
		representative probability sample of the British population to examine how
		Twitter and Facebook users differ from the general population in terms of
		demographics, political attitudes and political behaviour. We find that
		Twitter and Facebook users differ substantially from the general population
		on many politically relevant dimensions including vote choice, turnout, age,
		gender, and education. On average social media users are younger and better
		educated than non-users, and they are more liberal and pay more attention to
		politics. Despite paying more attention to politics, social media users are
		less likely to vote than non-users, but they are more likely to support the
		left leaning Labour Party when they do vote. However, we show that these
		apparent differences mostly arise due to the demographic composition of
		social media users. After controlling for age, gender, and education, no
		statistically significant differences arise between social media users and
		non-users on political attention, values or political behaviour.
	},
	file         = {:Users/ccrowe/Desktop/research/2053168017720008.pdf:pdf},
	keywords     = {
		British election study,Election
		forecasting,Facebook,Representativeness,Social media,Twitter
	},
}
@article{Curran2011,
	title        = {Advertising on Facebook},
	author       = {Curran, Kevin and Graham, Sarah and Temple, Christopher},
	year         = 2011,
	journal      = {International Journal of E-Business Development (IJED)},
	volume       = 26,
	number       = 1,
	pages        = {26--33},
	issn         = {2225-7411},
	abstract     = {
		-Approaches to advertising have changed dramatically over the past 50 years,
		from Newspapers to Mass media via Radio and Cinema, from Television sets to
		internet and e-mail. Now the next target is in sight-Social Networking. With
		advances in technology consumers are now in control of the media message they
		want to become exposed to. They have the option of watching TV programmes
		without having to view advertisements, they can listen to radio without
		having to hear the advertisements, they can alter their mail boxes so that
		SPAM mail goes directly to their junk folder and they can minimise advert pop
		ups when surfing online. Marketers are being forced to consider another form
		of marketing that would reach target customers in a new way. This paper
		examines how Facebook, has incorporated advertising into its site and
		highlights the methods employed to aid companies in reaching their customers
		in innovative ways.
	},
	file         = {:Users/ccrowe/Desktop/research/Advertising{\_}on{\_}Facebook.pdf:pdf},
	keywords     = {-Facebook,ads,advertising,social networks},
}
@article{DeBock2010,
	title        = {
		{Predicting website audience demographics forweb advertising targeting using
		multi-website clickstream data}
	},
	author       = {De Bock, Koenw and Van Den Poel, Dirk},
	year         = 2010,
	journal      = {Fundamenta Informaticae},
	volume       = 98,
	number       = 1,
	pages        = {49--70},
	doi          = {10.3233/FI-2010-216},
	issn         = {01692968},
	abstract     = {
		Several recent studies have explored the virtues of behavio ral targeting and
		personaliza- tion for online advertising. In this paper, we add to this lit
		erature by proposing a cost-effective methodology for the prediction of
		demographic website visi tor profiles that can be used for web advertising
		targeting purposes. The methodology involves the transformation of website
		visitors' clickstream patterns to a set of features and the training of
		Random Forest classifiers that generate predictions for gender, age, level of
		education and occupat ion category. These demographic predic- tions can
		support online advertisement targeting (i) as an a dditional input in
		personalized advertising or behavioral targeting, or (ii) as an input for
		aggregated d emographic website visitor profiles that support marketing
		managers in selecting websites and achie ving an optimal correspondence
		between target groups and website audience composition. The propos ed
		methodology is validated using data from a Belgian web metrics company. The
		results reveal that R andom Forests demonstrate superior classification
		performance over a set of benchmark algorith ms. Further, the ability of the
		model set to generate representative demographic website audience p rofiles
		is assessed. The stability of the models over time is demonstrated using
		out-of-period data.
	},
	file         = {:Users/ccrowe/Desktop/research/wp{\_}09{\_}618.pdf:pdf},
	keywords     = {
		Clickstream analysis,Demographic prediction,Demographic targeting,Ensemble
		classification,Out-of-period validation,Random Forests,Web advertising,Web
		user profiling
	},
}
@article{Clavio2014,
	title        = {Dimensions of Social Media Utilization Among College Sport Fans},
	author       = {Clavio, Galen and Walsh, Patrick},
	year         = 2014,
	journal      = {Communication {\&} Sport},
	volume       = 2,
	number       = 3,
	pages        = {261--281},
	doi          = {10.1177/2167479513480355},
	isbn         = 9781612890524,
	issn         = {2167-4795},
	url          = {http://journals.sagepub.com/doi/10.1177/2167479513480355},
	abstract     = {
		As social media provide athletic departments and their constituents with an
		additional point of engagement with their fans, it is important to understand
		the social media audience. However, despite the growth of social media use
		among collegiate athletic departments, coaches, and teams, relatively little
		is known about the individuals who are utilizing various social media forums.
		This study was the first to attempt to understand why college sport fans
		engage in sport-focused social media use, with a theoretical grounding in
		uses and gratifications. Utilizing a survey of student fans from a large
		Division 1 institution, the results suggest that there is a relatively low
		level of social media participation among college sport fans in relation to
		official Twitter and Facebook feeds of the team, and a surprising prevalence
		of traditional media usage for informational purposes. Factor analysis
		reveals dimen-sions of gratification for social media use include content
		creation as an identifiable factor. These and other findings are discussed.
	},
	file         = {
		
		:Users/ccrowe/Desktop/research/Dimensions{\_}of{\_}social{\_}media{\_}utilization{\_}a.pdf:pdf
	},
}
@article{Ruths2014,
	title        = {Social sciences. Social media for large studies of behavior},
	author       = {Ruths, Derek and Pfeffer, Jurgen},
	year         = 2014,
	journal      = {Science (New York, N.Y.)},
	volume       = 346,
	number       = 6213,
	pages        = {1063--1064},
	doi          = {10.1126/science.346.6213.1063},
	issn         = 10959203,
	abstract     = {
		Working with computational methods and large textual analysis has been
		challenging and very rewarding—with all the ups and downs that doing
		empirical social research entails. In my contribution, I relate some research
		experiences and reflect upon data construction and the links between theory,
		data, and methods.
	},
	file         = {:Users/ccrowe/Desktop/research/RuthsPfefferSocialMedia-Copy.pdf:pdf},
	pmid         = 25430759,
}
@article{Krizhevsky2012,
	title        = {ImageNet Classification with Deep Convolutional Neural Networks},
	author       = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	year         = 2012,
	journal      = {Advances In Neural Information Processing Systems},
	pages        = {1--9},
	doi          = {http://dx.doi.org/10.1016/j.protcy.2014.09.007},
	isbn         = 9781627480031,
	issn         = 10495258,
	abstract     = {
		We trained a large, deep convolutional neural network to classify the 1.2
		million high-resolution images in the ImageNet LSRVRC-2010 contest into the
		1000 different classes. On the test data, we achieved top-1 and top-5 error
		rates of 37.5{\%} and 17.0{\%} which is considerably better than the previous
		state of the art. The neural network, which has 60 million paramters and
		650,000 neurons, consists of five convolutional layers, some of which are
		followed by max-pooling layers, and three fully connected layers with a final
		1000-way softmax. To make training faster, we used non-saturating neurons and
		a very efficient GPU implementation of the convolutional operation. To reduce
		overfitting in the fully-connected layers, we employed a recently-developed
		method called 'dropout' that proved to be effective. We also entered a
		variant of the model in the ILSVRC-2012 competition and achievd a top-5 test
		error rate of 15.3{\%}, compared to 26.2{\%} achieved by the second-best
		entry.
	},
	archiveprefix = {arXiv},
	arxivid      = {1102.0183},
	eprint       = {1102.0183},
	file         = {
		
		:Users/ccrowe/Downloads/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf:pdf
	},
	pmid         = 7491034,
}
@article{Azizian2017,
	title        = {
		{Identifying Personal Messages: A Step towards Product/Service Review and
		Opinion Mining}
	},
	author       = {Azizian, Sasan and Rastegari, Elham and Ricks, Brain and Hall, Margeret},
	year         = 2017,
	journal      = {
		International Conference on Computational Science and Computational
		Intelligence
	},
	number       = {January 2018},
	file         = {:Users/ccrowe/Downloads/PersonalProfessional{\_}CameraReadyVersion.pdf:pdf},
	keywords     = {classification,data mining,features,healthcare,selection,twitter},
}
@article{Shavitt1998,
	title        = {Public Attitudes Toward Advertising : More Favorabie Than You Might Think},
	author       = {Shavitt, Sharon and Lowrey, Pamela M. and Haefner, James E.},
	year         = 1998,
	journal      = {Journal of Advertising Research},
	volume       = 38,
	number       = 4,
	pages        = {7--22},
	url          = {
		
		https://www.researchgate.net/publication/247294509{\_}Public{\_}Attitudes{\_}Toward{\_}Advertising{\_}More{\_}Favorable{\_}Than{\_}You{\_}Might{\_}Think
	},
	file         = {:Users/ccrowe/Downloads/PublicAttitudesTowardAdvertising.pdf:pdf},
}
@misc{Jar1998,
	title        = {JAR 1998.pdf},
	file         = {:Users/ccrowe/Downloads/JAR 1998.pdf:pdf},
}
@article{Schacht2015,
	title        = {Tweet if you will – the real question is , who do you influence ?},
	author       = {Schacht, Johanna and Hall, Margeret and Chorley, Martin},
	year         = 2015,
	number       = {June},
	doi          = {10.1145/2786451.2786923},
	file         = {:Users/ccrowe/Downloads/Ppaper.pdf:pdf},
}
@article{Lloret2011,
	title        = {Fo r P ee r R},
	year         = 2011,
	volume       = 24,
	pages        = {145--151},
	doi          = {10.1108/08880451111169223.The},
	isbn         = {0888045111116},
	file         = {:Users/ccrowe/Downloads/Lloret - ROI - autor.pdf:pdf},
}
@article{Wright2010,
	title        = {The Lasting Effects Of Social Media Trends On Advertising},
	author       = {
		Wright, Elizabeth and Khanfar, Nile M. and Harrington, Catherine and Kizer,
		Lee E.
	},
	year         = 2010,
	journal      = {Journal of Business {\&} Economics Research (JBER)},
	volume       = 8,
	number       = 11,
	doi          = {10.19030/jber.v8i11.50},
	isbn         = {1542-4448},
	issn         = {2157-8893},
	url          = {http://www.cluteinstitute.com/ojs/index.php/JBER/article/view/50},
	abstract     = {
		{\textless}p{\textgreater}{\textless}p style="text-align: justify; margin:
		0in 0.5in 0pt; mso-pagination: none;"{\textgreater}{\textless}em
		style="mso-bidi-font-style: normal;"{\textgreater}{\textless}span
		style="font-size: 10pt;"{\textgreater}{\textless}span style="font-family:
		Times New Roman;"{\textgreater}Americans are exposed to an astounding number
		of advertising messages every day.{\textless}span style="mso-spacerun:
		yes;"{\textgreater}  {\textless}/span{\textgreater}The result of this
		bombardment of advertising on society is that consumers have become
		increasingly resistant to traditional forms of advertising.{\textless}span
		style="mso-spacerun: yes;"{\textgreater}  {\textless}/span{\textgreater}After
		spending millions of dollars on mass advertising that consumers tend to block
		out and ignore, marketers have re-evaluated their advertising methods and are
		following holistic marketing concepts that focus on customer relationship
		marketing and more creative, understated ads instead of in-your-face
		billboards and loud television segments.{\textless}span style="mso-spacerun:
		yes;"{\textgreater}  {\textless}/span{\textgreater}This paper explores social
		media trends, including social media opportunities and mobile marketing, and
		the potentially lasting effects that these trends have on
		advertising{\textless}strong style="mso-bidi-font-weight:
		normal;"{\textgreater}.{\textless}/strong{\textgreater}{\textless}/span{\textgreater}{\textless}/span{\textgreater}{\textless}/em{\textgreater}{\textless}/p{\textgreater}{\textless}/p{\textgreater}
	},
	file         = {
		:Users/ccrowe/Documents/Thesis/facebook{\_}api/ROI
		Papers/TheLastingEffectsOfSocialMediaTrendsOnAdvertising.pdf:pdf
	},
}
@article{Hoffman2010,
	title        = {Can You Measure the ROI of Your Social Media Marketing?},
	author       = {Hoffman, Dl D.L. Donna L and Fodor, Marek},
	year         = 2010,
	journal      = {MIT Sloan Management Review},
	volume       = 52,
	number       = 1,
	pages        = {41--49},
	doi          = {10.1287/mksc.1120.0768},
	url          = {
		
		http://www.mitsmr-ezine.com/mitsmriphone11/fall2010/m2/MobileArticle.action?articleId=23732{\&}mobileWeb=true{\&}lm=1285614348000{\%}5Cnhttp://www.emarketingtravel.net/resources/can
		you mesur the ROI of your Social media
		marketing.pdf{\%}5Cnhttp://sloanreview.mit
	},
	abstract     = {
		You can. But it requires a new set of measurements that begins with tracking
		the customers investments not yours.
	},
	archiveprefix = {arXiv},
	arxivid      = {arXiv:1011.1669v3},
	eprint       = {arXiv:1011.1669v3},
	file         = {
		:Users/ccrowe/Documents/Thesis/facebook{\_}api/ROI
		Papers/TEXTO{\_}AULA{\_}10{\_}Can You Measure the ROI of Your Social Media
		Marketing.pdf:pdf
	},
	pmid         = 78434266,
}
@article{Fisher2009,
	title        = {ROI in social media: A look at the arguments},
	author       = {Fisher, Tia},
	year         = 2009,
	journal      = {Journal of Database Marketing and Customer Strategy Management},
	volume       = 16,
	number       = 3,
	pages        = {189--195},
	doi          = {10.1057/dbm.2009.16},
	isbn         = {1741-2439},
	issn         = 17412439,
	abstract     = {
		Return on Investment (ROI) has become the Holy Grail of social media.
		Marketers are being squeezed between admonishments to participate in the vast
		new online communications available to them and demands to justify the cost
		using conventional advertising metrics. New ‘ ROI calculators ' are being
		created almost as fast as new social networking sites – then just as quickly
		being dismissed as being unworkable. In this article, Tia Fisher of
		eModeration takes a long view of the current state of ROI in social media,
		and examines the arguments for and against attempting to use any kind of
		metric to justify involvement in a social media program.
	},
	file         = {
		:Users/ccrowe/Documents/Thesis/facebook{\_}api/ROI
		Papers/Fisher2009{\_}Article{\_}ROIInSocialMediaALookAtTheArgu.pdf:pdf
	},
	keywords     = {Marketing,Marketing budgets,ROI,Social media},
	pmid         = 44194163,
}
@article{Dwivedi2015,
	title        = {Social media marketing and advertising},
	author       = {Dwivedi, Yogesh K. and Kapoor, Kawaljeet Kaur and Chen, Hsin},
	year         = 2015,
	journal      = {The Marketing Review},
	volume       = 15,
	number       = 3,
	pages        = {289--309},
	doi          = {10.1362/146934715X14441363377999},
	issn         = {1469347X},
	url          = {
		
		http://openurl.ingenta.com/content/xref?genre=article{\&}issn=1469-347X{\&}volume=15{\&}issue=3{\&}spage=289
	},
	file         = {
		:Users/ccrowe/Documents/Thesis/facebook{\_}api/ROI
		Papers/FINALACCEPTED.pdf:pdf
	},
}
@article{Tiago2014,
	title        = {Digital marketing and social media: Why bother?},
	author       = {
		Tiago, Maria Teresa Pinheiro Melo Borges and Verissimo, Jose Manuel Cristovao
	},
	year         = 2014,
	journal      = {Business Horizons},
	volume       = 57,
	number       = 6,
	pages        = {703--708},
	doi          = {10.1016/j.bushor.2014.07.002},
	isbn         = {0007-6813},
	issn         = {00076813},
	abstract     = {
		Changes in consumer behavior require firms to rethink their marketing
		strategies in the digital domain. Currently, a significant portion of the
		associated research is focused more on the customer than on the firm. To
		redress this shortcoming, this study adopts the perspective of the firm to
		facilitate an understanding of digital marketing and social media usage as
		well as its benefits and inhibitors. The second generation of Internet-based
		applications enhances marketing efforts by allowing firms to implement
		innovative forms of communication and co-create content with their customers.
		Based on a survey of marketing managers, this article shows that firms face
		internal and external pressures to adopt a digital presence in social media
		platforms. Firms' digital marketing engagement can be categorized according
		to perceived benefits and digital marketing usage. To improve digital
		marketing engagement, marketers must focus on relationship-based interactions
		with their customers. This article demonstrates how some firms are already
		accomplishing just that.
	},
	file         = {
		:Users/ccrowe/Documents/Thesis/facebook{\_}api/ROI
		Papers/1-s2.0-S0007681314000949-main.pdf:pdf
	},
	keywords     = {Budget spending,Digital marketing,Digital media trends,Social metrics},
}
@article{Gao2005,
	title        = {
		{Web image clustering by consistent utilization of visual features and
		surrounding texts}
	},
	author       = {
		Gao, Bin and Liu, Tie-Yan and Qin, Tao and Zheng, Xin and Cheng, Qian-Sheng
		and Ma, Wei-Ying
	},
	year         = 2005,
	journal      = {
		Proceedings of the 13th annual ACM international conference on Multimedia -
		MULTIMEDIA '05
	},
	pages        = 112,
	doi          = {10.1145/1101149.1101167},
	isbn         = 1595930442,
	url          = {http://dl.acm.org/citation.cfm?id=1101149.1101167},
	abstract     = {
		Authors propose to exploit both low visual features and text for clustering.
		They called this method consistent bipartite graph co-partitioning which
		cluster web images based on the fusion. They formulate a multi-objective
		optimization problem, which can be solved by semi-definite programming (SDP).
		Authors based their propose on the use of spectral clustering and bipartite
		spectral clustering partition. The algorithm proposed is called F-I-T
		(low-level Features, Images, Terms in surrounding texts). In the
		experimentation they crawled the Photography Museums and Galleries of the
		Yahoo Directory.
	},
	file         = {
		:Users/ccrowe/Documents/Thesis/facebook{\_}api/Thesis{\_}Proposal/Related
		Work Papers/ACMMM2005.pdf:pdf
	},
	keywords     = {co-clustering,consistency,image processing,spectral graph},
}
@article{Mandhyani2017,
	title        = {Image Sentiment Analysis},
	author       = {
		Mandhyani, Jayesh and Khatri, Latika and Ludhrani, Varsha and Nagdev, Raveena
		and Sahu, Prof Sunita
	},
	year         = 2017,
	journal      = {International Journal of Engineering Science and Computing},
	volume       = 7,
	number       = 2,
	pages        = {4566--4569},
	abstract     = {
		It is true that a picture is worth a thousand words. The use of images to
		express views, opinions, feelings, emotions and sentiments has increased
		tremendously on social platforms like Flickr, Instagram, Twitter, Tumblr,
		etc. The analysis of sentiments in us er- generated images is of increasing
		importance for developing several applications. A lot of research work has
		been done for sentiment analysis of textual data; there has been very limited
		work that focuses on analyzing sentiment of image data. In this work, we
		propose a model based on the mid-level features of the images that combines
		the techniques of SentiBank, RCNN (Regions with CNN) and SentiSt rength.
		Results of experiments conducted on Flickr image dataset show that this
		approach achieves better sentiment classification accuracy.
	},
	file         = {
		:Users/ccrowe/Documents/Thesis/facebook{\_}api/Thesis{\_}Proposal/Related
		Work Papers/551d641a6711d6c0c0deadacb3cfc168.Image Sentiment Analysis.pdf:pdf
	},
	keywords     = {
		anp,image sentiment analysis,rrcnn,s,sentibank,sentistrength,visual sentiment
		ontology
	},
}
@article{Kanan2012,
	title        = {Color-to-grayscale: Does the method matter in image recognition?},
	author       = {Kanan, Christopher and Cottrell, Garrison W.},
	year         = 2012,
	journal      = {PLoS ONE},
	volume       = 7,
	number       = 1,
	doi          = {10.1371/journal.pone.0029740},
	issn         = 19326203,
	abstract     = {
		In image recognition it is often assumed the method used to convert color
		images to grayscale has little impact on recognition performance. We compare
		thirteen different grayscale algorithms with four types of image descriptors
		and demonstrate that this assumption is wrong: not all color-to-grayscale
		algorithms work equally well, even when using descriptors that are robust to
		changes in illumination. These methods are tested using a modern
		descriptor-based image recognition framework, on face, object, and texture
		datasets, with relatively few training instances. We identify a simple method
		that generally works best for face and object recognition, and two that work
		well for recognizing textures.
	},
	file         = {
		:Users/ccrowe/Documents/Thesis/facebook{\_}api/Thesis{\_}Proposal/Related
		Work Papers/pone.0029740.pdf:pdf
	},
	pmid         = 22253768,
}
@article{Tang,
	title        = {Robust Boltzmann Machines for Recognition and Denoising.(2012).pdf},
	author       = {Tang, Yichuan and Hinton, Geoffrey},
	file         = {
		:Users/ccrowe/Documents/Thesis/facebook{\_}api/Thesis{\_}Proposal/Related
		Work Papers/robm.pdf:pdf
	},
}
@article{Liu2012,
	title        = {Sentiment Analysis and Opinion Mining},
	author       = {Liu, Bing},
	year         = 2012,
	number       = {May},
	pages        = {1--108},
	doi          = {10.2200/S00416ED1V01Y201204HLT016},
	isbn         = 9781608458844,
	issn         = {1947-4040},
	abstract     = {http://www.morganclaypool.com/doi/abs/10.2200/S00416ED1V01Y201204HLT016},
	archiveprefix = {arXiv},
	arxivid      = {1003.5699},
	eprint       = {1003.5699},
	file         = {
		:Users/ccrowe/Documents/Thesis/facebook{\_}api/Thesis{\_}Proposal/Related
		Work Papers/SentimentAnalysis-and-OpinionMining.pdf:pdf
	},
	pmid         = 791643259,
}
@article{Li2017,
	title        = {Diversified Texture Synthesis with Feed-forward Networks},
	author       = {
		Li, Yijun and Fang, Chen and Yang, Jimei and Wang, Zhaowen and Lu, Xin and
		Yang, Ming-Hsuan
	},
	year         = 2017,
	doi          = {10.1109/CVPR.2017.36},
	isbn         = {978-1-5386-0457-1},
	issn         = {1063-6919},
	url          = {http://arxiv.org/abs/1703.01664},
	abstract     = {
		Recent progresses on deep discriminative and generative modeling have shown
		promising results on texture synthesis. However, existing feed-forward based
		methods trade off generality for efficiency, which suffer from many issues,
		such as shortage of generality (i.e., build one network per texture), lack of
		diversity (i.e., always produce visually identical output) and suboptimality
		(i.e., generate less satisfying visual effects). In this work, we focus on
		solving these issues for improved texture synthesis. We propose a deep
		generative feed-forward network which enables efficient synthesis of multiple
		textures within one single network and meaningful interpolation between them.
		Meanwhile, a suite of important techniques are introduced to achieve better
		convergence and diversity. With extensive experiments, we demonstrate the
		effectiveness of the proposed model and techniques for synthesizing a large
		number of textures and show its applications with the stylization.
	},
	archiveprefix = {arXiv},
	arxivid      = {1703.01664},
	eprint       = {1703.01664},
	file         = {
		:Users/ccrowe/Documents/Thesis/facebook{\_}api/Thesis{\_}Proposal/Related
		Work Papers/1703.01664.pdf:pdf
	},
}
@article{Ohsawa2013,
	title        = {
		{Like Prediction: Modeling Like Counts by Bridging Facebook Pages with Linked
		Data}
	},
	author       = {Ohsawa, Shohei and Matsuo, Yutaka},
	year         = 2013,
	journal      = {
		Proceedings of the 22Nd International Conference on World Wide Web Companion
	},
	pages        = {541--548},
	doi          = {10.1145/2487788.2487992},
	isbn         = {978-1-4503-2038-2},
	url          = {http://dl.acm.org/citation.cfm?id=2487788.2487992},
	abstract     = {
		Recent growth of social media has produced a new market for branding of
		people and businesses. Facebook provides Facebook Pages (Pages in short) for
		public figures and businesses (we call entities) to communicate with their
		fans through a Like button. Because Like counts sometimes reflect the
		popularity of entities, techniques to increase the Like count can be a matter
		of interest, and might be known as social media marketing. From an academic
		perspective, Like counts of Pages depend not only on the popularity of the
		entity, but also on the popularity of semantically related entities. For
		example, Lady Gaga's Page has many Likes; her song "Poker Face" does too. We
		can infer that her next song will acquire many Likes immediately. Important
		questions are these: How does the Like count of Lady Gaga affect the Like
		count of her song? Alternatively, how does the Like count of her song
		constitute some fraction of the Like count of Lady Gaga herself? As described
		in this paper, we strive to reveal the mutual influences of Like counts among
		semantically related entities. To measure the influence of related entities,
		we propose a problem called the Like prediction problem (LPP). It models Like
		counts of a given entity using information of related entities. The semantic
		relations among entities, expressed as RDF predicates, are obtained by
		linking each Page with the most similar DBpedia entity. Using the model
		learned by support vector regression (SVR) on LPP, we can estimate the Like
		count of a new entity e.g., Lady Gaga's new song. More importantly, we can
		analyze which RDF predicates are important to infer Like counts, providing a
		mutual influence network among entities. Our study comprises three parts: (1)
		crawling the Pages and their Like counts, (2) linking Pages to DBpedia, and
		(3) constructing features to solve the LPP. Our study, based on 20 million
		Pages with 30 billion Likes, is the largest-scale study of Facebook Likes
		ever reported. This research constitutes a new attempt to integrate
		unstructured emotional data such as Likes, with Linked data, and to provide
		new insights for branding with social media.
	},
	file         = {
		:Users/ccrowe/Documents/Thesis/facebook{\_}api/Thesis{\_}Proposal/Related
		Work Papers/p541.pdf:pdf
	},
	keywords     = {
		entity linking,facebook,feature construction,link-based prediction,linked
		data
	},
}
@article{Simonyan2015,
	title        = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
	author       = {Simonyan, Karen and Zisserman, Andrew},
	year         = 2015,
	journal      = {International Conference on Learning Representations (ICRL)},
	pages        = {1--14},
	doi          = {10.1016/j.infsof.2008.09.005},
	isbn         = 9781450341448,
	issn         = {09505849},
	url          = {http://arxiv.org/abs/1409.1556},
	abstract     = {
		In this work we investigate the effect of the convolutional network depth on
		its accuracy in the large-scale image recognition setting. Our main
		contribution is a thorough evaluation of networks of increasing depth using
		an architecture with very small (3x3) convolution filters, which shows that a
		significant improvement on the prior-art configurations can be achieved by
		pushing the depth to 16-19 weight layers. These findings were the basis of
		our ImageNet Challenge 2014 submission, where our team secured the first and
		the second places in the localisation and classification tracks respectively.
		We also show that our representations generalise well to other datasets,
		where they achieve state-of-the-art results. We have made our two
		best-performing ConvNet models publicly available to facilitate further
		research on the use of deep visual representations in computer vision.
	},
	archiveprefix = {arXiv},
	arxivid      = {1409.1556},
	eprint       = {1409.1556},
	file         = {:Users/ccrowe/Downloads/convert/1409.1556.pdf:pdf},
	pmid         = 16873662,
}
@misc{smith_anderson_smith_anderson_2019,
	title        = {Social Media Use 2018: Demographics and Statistics},
	author       = {Smith, Aaron and Anderson, Monica and Smith, Aaron and Anderson, Monica},
	year         = 2019,
	month        = 4,
	journal      = {Pew Research Center: Internet, Science & Tech},
	publisher    = {Pew Research Center: Internet, Science & Tech},
	url          = {https://www.pewinternet.org/2018/03/01/social-media-use-in-2018/},
}
@misc{statista,
	title        = {Facebook ad spend 2018  Statistic},
	author       = {statista},
	journal      = {Statista},
	url          = {https://www.statista.com/statistics/685531/facebook-ad-expense/},
}
@article{Matas,
	title        = {Robust Wide Baseline Stereo from Maximally Stable Extremal Regions},
	author       = {Matas, J and Chum, O and Urban, M and Pajdla, T},
	pages        = {384--393},
	file         = {:Users/ccrowe/Downloads/matas-bmvc02.pdf:pdf},
}
@article{Sojka2004,
	title        = {Software Framework for Topic Modelling with Large Corpora},
	author       = {Sojka, Petr},
	year         = 2004,
	file         = {:Users/ccrowe/Downloads/lrec2010{\_}final.pdf:pdf},
}
@book{whitenack_2017,
	title        = {
		Machine learning with Go: implement regression, classification, clustering,
		time-series models, neural networks, and more using the Go programming
		language
	},
	author       = {Whitenack, Daniel},
	year         = 2017,
	publisher    = {Packt},
	place        = {Birmingham ; Mumbai},
}
@article{Gilbert,
	title        = {
		{VADER : A Parsimonious Rule-based Model for Sentiment Analysis of Social
		Media Text}
	},
	author       = {Gilbert, Eric},
	file         = {:Users/ccrowe/Downloads/icwsm14.vader.hutto.pdf:pdf},
}
@article{Kouloumpis2011,
	title        = {Twitter Sentiment Analysis : The Good the Bad and the OMG !},
	author       = {Kouloumpis, Efthymios and Wilson, Theresa and Moore, Johanna},
	year         = 2011,
	pages        = {538--541},
	file         = {:Users/ccrowe/Downloads/sentiment.pdf:pdf},
	keywords     = {Poster Papers},
}
@article{Miguel2006,
	title        = {Fast Nonparametric Clustering with Gaussian Blurring Mean-Shift},
	author       = {Miguel, A and Csee, Miguel and Edu, O G I},
	year         = 2006,
	number       = 2,
	file         = {:Users/ccrowe/Downloads/gaussian{\_}blurring.pdf:pdf},
}
@article{Straton2015,
	title        = {
		{Big Social Data Analytics for Public Health : Predicting Facebook Post
		Performance using Artificial Neural Networks and Deep Learning}
	},
	author       = {Straton, Nadiya and Mukkamala, Raghava Rao and Vatrapu, Ravi},
	year         = 2015,
}
@article{Li2015,
	title        = {{Click-through Prediction for Advertising in Twitter Timeline}},
	author       = {Li, Cheng and Lu, Yue and Mei, Qiaozhu and Wang, Dong and Pandey, Sandeep},
	year         = 2015,
	journal      = {
		Proceedings of the 21th ACM SIGKDD International Conference on Knowledge
		Discovery and Data Mining - KDD '15
	},
	pages        = {1959--1968},
	doi          = {10.1145/2783258.2788582},
	isbn         = 9781450336642,
	url          = {http://dl.acm.org/citation.cfm?doid=2783258.2788582},
	abstract     = {
		We present the problem of click-through prediction for advertis-ing in
		Twitter timeline, which displays a stream of Tweets from accounts a user
		choose to follow. Traditional computational adver-tising usually appears in
		two forms: sponsored search that places ads onto the search result page when
		a query is issued to a search engine, and contextual advertising that places
		ads onto a regular, usually static Web page. Compared with these two
		paradigms, placing ads into a Tweet stream is particularly challenging given
		the nature of the data stream: the context into which an ad can be placed
		updates dynamically and never replicates. Every ad is therefore placed into a
		unique context. This makes the information available for training a machine
		learning model extremely sparse. In this study, we propose a learning-to-rank
		method which not only addresses the sparsity of training signals but also can
		be trained and updated online. The proposed method is evaluated using both
		offline experiments and online A/B tests, which involve very large
		collections of Twitter data and real Twitter users. Results of the
		experiments prove the effectiveness and efficiency of our solution, and its
		superiority over the current production model adopted by Twitter.
	},
	keywords     = {click-through predic-,online advertising,social media stream},
}
@article{Wang2015,
	title        = {{Unsupervised sentiment analysis for social media images}},
	author       = {Wang, Yilin and Wang, Suhang and Tang, Jiliang and Liu, Huan and Li, Baoxin},
	year         = 2015,
	journal      = {Proceedings of the 24th International Conference on Artificial Intelligence},
	pages        = {2378--2379},
	isbn         = 9781577357384,
	url          = {https://arxiv.org/abs/1604.03489},
	abstract     = {
		Recently text-based sentiment prediction has been extensively studied, while
		image-centric sentiment analysis receives much less attention. In this
		pa-per, we study the problem of understanding human sentiments from
		large-scale social media images, considering both visual content and
		contextual in-formation, such as comments on the images, cap-tions, etc. The
		challenge of this problem lies in the " semantic gap " between low-level
		visual fea-tures and higher-level image sentiments. Moreover, the lack of
		proper annotations/labels in the major-ity of social media images presents
		another chal-lenge. To address these two challenges, we propose a novel
		Unsupervised SEntiment Analysis (USEA) framework for social media images. Our
		approach exploits relations among visual content and rele-vant contextual
		information to bridge the " semantic gap " in the prediction of image
		sentiments. With experiments on two large-scale datasets, we show that the
		proposed method is effective in addressing the two challenges.
	},
}
@article{Hassner2015,
	title        = {{Age and Gender Classification using Convolutional Neural Networks}},
	author       = {Hassner, Gil Levi and Tal},
	year         = 2015,
	journal      = {
		2008 8th IEEE International Conference on Automatic Face and Gesture
		Recognition, FG 2008
	},
	volume       = 24,
	number       = 3,
	pages        = {2622--2629},
	doi          = {10.1109/AFGR.2008.4813314},
	isbn         = 9781424421541,
	issn         = {01628828},
	url          = {
		
		http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4761364%5Cnhttp://portal.acm.org/citation.cfm?doid=1180639.1180711%5Cnhttp://www.ncbi.nlm.nih.gov/pubmed/21193381%5Cnhttp://dx.doi.org/10.1016/j.patcog.2012.09.011
	},
	abstract     = {
		A key point in automatic age estimation is to design feature set essential to
		age perception. To achieve this goal, this paper builds up a hierarchical
		graphical face model for faces appearing at low, middle and high resolution
		respectively. Along the hierarchy, a face image is decomposed into detailed
		parts from coarse to fine. Then four types of features are extracted from
		this graph representation guided by the priors of aging process embedded in
		the graphical model: topology, geometry, photometry and configuration. On age
		estimation, this paper follows the popular regression formulation for mapping
		feature vectors to its age label. The effectiveness of the presented feature
		set is justified by testing results on two datasets using different kinds of
		regression methods. The experimental results in this paper show that
		designing feature set for age estimation under the guidance of hierarchical
		face model is a promising method and a flexible framework as well.
	},
	file         = {
		:Users/ccrowe/Library/Application Support/Mendeley Desktop/Downloaded/Hassner
		- 2015 - Age and Gender Classification using Convolutional Neural
		Networks.pdf:pdf
	},
	keywords     = {
		Age estimation,Age manifold,Aging,Aging variation,Algorithms,Artificial
		Intelligence,Automated,Automated: methods,Biological,Biometry,Biometry:
		methods,Computer Simulation,Computer
		vision,Computer-Assisted,Computer-Assisted: methods,Conformal embedding
		analysis,Crowd density estimation,Cumulative attributes,Dimensionality
		reduction,Distance metric learning,Face,Face aging,Face and gesture
		recognition,Face recognition,Face: anatomy & histology,Human age
		estimation,Humans,Image Enhancement,Image Enhancement: methods,Image
		Interpretation,Image classification,Local regression,Locally adjusted robust
		regression,Machine learning,Manifold,Manifold learning,Models,Multiple linear
		regression,Neural networks,Nonlinear regression,Ordinal ranking,Pattern
		Recognition,Pattern recognition,Reproducibility of Results,Sensitivity and
		Specificity,Statistical face models,Subspace learning,Support vector machine
		(SVM),Support vector regression (SVR),active appearance model,age
		estimation,age progression,age specific human-computer interaction,age
		synthesis,aging pattern,all or part of,automatic age,binary
		classification,estimation,face image,face recognition,facial image
		processing,human age estimation,label distribution,machine learning,or hard
		copies of,permission to make digital,ranking,scattering transform,survey,this
		work for
	},
	pmid         = 25576566,
}
@article{Poria2016,
	title        = {
		A Deeper Look into Sarcastic Tweets Using Deep Convolutional Neural Networks
	},
	author       = {Poria, Soujanya and Cambria, Erik and Hazarika, Devamanyu and Vij, Prateek},
	year         = 2016,
	abstract     = {
		Sarcasm detection is a key task for many natural language processing tasks.
		In sentiment analysis, for example, sarcasm can flip the polarity of an
		"apparently positive" sentence and, hence, negatively affect polarity
		detection performance. To date, most approaches to sarcasm detection have
		treated the task primarily as a text categorization problem. Sarcasm,
		however, can be expressed in very subtle ways and requires a deeper
		understanding of natural language that standard text categorization
		techniques cannot grasp. In this work, we develop models based on a
		pre-trained convolutional neural network for extracting sentiment, emotion
		and personality features for sarcasm detection. Such features, along with the
		network's baseline features, allow the proposed models to outperform the
		state of the art on benchmark datasets. We also address the often ignored
		generalizability issue of classifying data that have not been seen by the
		models at learning phase.
	},
	archiveprefix = {arXiv},
	arxivid      = {1610.08815},
	eprint       = {1610.08815},
	file         = {
		:Users/ccrowe/Library/Application Support/Mendeley Desktop/Downloaded/Poria
		et al. - 2016 - A Deeper Look into Sarcastic Tweets Using Deep Convolutional
		Neural Networks.pdf:pdf
	},
}
@article{Khosla2014,
	title        = {{What Makes an Image Popular ?}},
	author       = {Khosla, Aditya and {Das Sarma}, Atish and Hamid, Raffay},
	year         = 2014,
	journal      = {Proceedings of the 23rd International Conference on World Wide Web},
	pages        = {867----876},
	doi          = {10.1145/2566486.2567996},
	isbn         = 9781450327442,
	issn         = 9781450327442,
	url          = {http://dl.acm.org/citation.cfm?id=2567996},
	abstract     = {
		Hundreds of thousands of photographs are uploaded to the internet every
		minute through various social networking and photo sharing platforms. While
		some images get millions of views, others are completely ignored. Even from
		the same users, different photographs receive different number of views. This
		begs the question: What makes a photograph popular? Can we predict the number
		of views a photograph will receive even before it is uploaded? These are some
		of the questions we address in this work. We investigate two key components
		of an image that affect its popularity, namely the image content and social
		context. Using a dataset of about 2.3 million images from Flickr, we
		demonstrate that we can reliably predict the normalized view count of images
		with a rank correlation of 0.81 using both image content and social cues. In
		this paper, we show the importance of image cues such as color, gradients,
		deep learning features and the set of objects present, as well as the
		importance of various social cues such as number of friends or number of
		photos uploaded that lead to high or low popularity of images.
	},
	archiveprefix = {arXiv},
	arxivid      = {arXiv:1011.1669v3},
	eprint       = {arXiv:1011.1669v3},
	file         = {
		:Users/ccrowe/Library/Application Support/Mendeley Desktop/Downloaded/Khosla,
		Das Sarma, Hamid - 2014 - What Makes an Image Popular.pdf:pdf
	},
	keywords     = {deep learning,flickr,images,popularity,regression},
	pmid         = 15003161,
}
@article{Chen2014,
	title        = {
		DeepSentiBank: Visual Sentiment Concept Classification with Deep
		Convolutional Neural Networks
	},
	author       = {Chen, Tao and Borth, Damian and Darrell, Trevor and Chang, Shih-Fu},
	year         = 2014,
	isbn         = 9781509040452,
	archiveprefix = {arXiv},
	arxivid      = {1410.8586},
	eprint       = {1410.8586},
	file         = {
		:Users/ccrowe/Library/Application Support/Mendeley Desktop/Downloaded/Chen et
		al. - 2014 - DeepSentiBank Visual Sentiment Concept Classification with Deep
		Convolutional Neural Networks.pdf:pdf
	},
	keywords     = {affective computing,deep learning,visual sentiment},
}
@article{Xu2014,
abstract = {Images have become one of the most popular types of media through which users convey their emotions within online social networks. Although vast amount of research is devoted to sentiment analysis of textual data, there has been very limited work that focuses on analyzing sentiment of image data. In this work, we propose a novel visual sentiment prediction framework that performs image understanding with Deep Convolutional Neural Networks (CNN). Specifically, the proposed sentiment prediction framework performs transfer learning from a CNN with millions of parameters, which is pre-trained on large-scale data for object recognition. Experiments conducted on two real-world datasets from Twitter and Tumblr demonstrate the effectiveness of the proposed visual sentiment analysis framework.},
archivePrefix = {arXiv},
arxivId = {1411.5731},
author = {Xu, Can and Cetintas, Suleyman and Lee, Kuang-Chih and Li, Li-Jia},
eprint = {1411.5731},
file = {:Users/ccrowe/Library/Application Support/Mendeley Desktop/Downloaded/Xu et al. - 2014 - Visual Sentiment Prediction with Deep Convolutional Neural Networks.pdf:pdf},
title = {Visual Sentiment Prediction with Deep Convolutional Neural Networks},
year = {2014}
}
@article{Lin2014,
	title        = {
		{User-level psychological stress detection from social media using deep
		neural network}
	},
	author       = {
		Lin, Huijie and Jia, Jia and Guo, Quan and Xue, Yuanyuan and Li, Qi and
		Huang, Jie and Cai, Lianhong and Feng, Ling
	},
	year         = 2014,
	journal      = {Proceedings of the ACM International Conference on Multimedia - MM '14},
	pages        = {507--516},
	doi          = {10.1145/2647868.2654945},
	isbn         = 9781450330633,
	url          = {http://dl.acm.org/citation.cfm?doid=2647868.2654945},
	abstract     = {
		It is of significant importance to detect and manage stress before it turns
		into severe problems. However, existing stress detection methods usually rely
		on psychological scales or physiological devices, making the detection
		complicated and costly. In this paper, we explore to automatically detect
		individuals' psychological stress via social media. Employing real online
		micro-blog data, we first investigate the correlations between users' stress
		and their tweeting content, social engagement and behavior patterns. Then we
		define two types of stress-related attributes: 1) low-level content
		attributes from a single tweet, including text, images and social
		interactions; 2) user-scope statistical attributes through their weekly
		micro-blog postings, leveraging information of tweeting time, tweeting types
		and linguistic styles. To combine content attributes with statistical
		attributes, we further design a convolutional neural network (CNN) with cross
		autoencoders to generate user-scope content attributes from low-level content
		attributes. Finally, we propose a deep neural network (DNN) model to
		incorporate the two types of user-scope attributes to detect users'
		psychological stress. We test the trained model on four different datasets
		from major micro-blog platforms including Sina Weibo, Tencent Weibo and
		Twitter. Experimental results show that the proposed model is effective and
		efficient on detecting psychological stress from micro-blog data. We believe
		our model would be useful in developing stress detection tools for mental
		health agencies and individuals.
	},
	file         = {
		:Users/ccrowe/Library/Application Support/Mendeley Desktop/Downloaded/Lin et
		al. - 2014 - User-level psychological stress detection from social media
		using deep neural network.pdf:pdf
	},
}
@article{Segalin2017,
	title        = {
		{Social profiling through image understanding: Personality inference using
		convolutional neural networks}
	},
	author       = {Segalin, Cristina and Cheng, Dong Seon and Cristani, Marco},
	year         = 2017,
	month        = {mar},
	journal      = {Computer Vision and Image Understanding},
	publisher    = {Academic Press},
	volume       = 156,
	pages        = {34--50},
	doi          = {10.1016/J.CVIU.2016.10.013},
	issn         = {1077-3142},
	url          = {https://www.sciencedirect.com/science/article/pii/S1077314216301679},
	abstract     = {
		The role of images in the last ten years has changed radically due to the
		advent of social networks: from media objects mainly used to communicate
		visual information, images have become personal, associated with the people
		that create or interact with them (for example, giving a “like”). Therefore,
		in the same way that a post reveals something of its author, so now the
		images associated to a person may embed some of her individual
		characteristics, such as her personality traits. In this paper, we explore
		this new level of image understanding with the ultimate goal of relating a
		set of image preferences to personality traits by using a deep learning
		framework. In particular, our problem focuses on inferring both self-assessed
		(how the personality traits of a person can be guessed from her preferred
		image) and attributed traits (what impressions in terms of personality traits
		these images trigger in unacquainted people), learning a sort of wisdom of
		the crowds. Our characterization of each image is locked within the layers of
		a CNN, allowing us to discover more entangled attributes (aesthetic patterns
		and semantic information) and to better generalize the patterns that identify
		a trait. The experimental results show that the proposed method outperforms
		state-of-the-art results and captures what visually characterizes a certain
		trait: using a deconvolution strategy we found a clear distinction of
		features, patterns and content between low and high values in a given trait.
	},
}
@article{Gelli2015,
	title        = {
		{Image Popularity Prediction in Social Media Using Sentiment and Context
		Features}
	},
	author       = {
		Gelli, Francesco and Uricchio, Tiberio and Bertini, Marco and {Del Bimbo},
		Alberto and Chang, Shih-Fu
	},
	year         = 2015,
	journal      = {Proceedings of the 23rd ACM international conference on Multimedia - MM '15},
	pages        = {907--910},
	doi          = {10.1145/2733373.2806361},
	isbn         = 9781450334594,
	url          = {http://dl.acm.org/citation.cfm?doid=2733373.2806361},
	abstract     = {
		{\textcopyright} 2015 ACM.Images in social networks share difierent
		destinies: some are going to become popular while others are going to be
		com-pletely unnoticed. In this paper we propose to use visual sentiment
		features together with three novel context fea-tures to predict a concise
		popularity score of social images. Experiments on large scale datasets show
		the benefits of proposed features on the performance of image popularity
		prediction. Exploiting state-of-The-Art sentiment features, we report a
		qualitative analysis of which sentiments seem to be related to good or poor
		popularity. To the best of our knowledge, this is the first work
		understanding specific visual sentiments that positively or negatively
		inuence the eventual popularity of images.
	},
	file         = {
		:Users/ccrowe/Library/Application Support/Mendeley Desktop/Downloaded/Gelli
		et al. - 2015 - Image Popularity Prediction in Social Media Using Sentiment
		and Context Features.pdf:pdf
	},
	keywords     = {affec-,image popularity,social networks,visual sentiment},
}
@article{Georgiou2015,
abstract = {Sentiment analysis is an emerging discipline with many analytical tools available. This project aimed to examine a number of tools regarding their suitability for healthcare data. A comparison between commercial and non-commercial tools was made using responses from an online survey which evaluated design changes made to a clinical information service. The commercial tools were Semantria and TheySay and the noncommercial tools were WEKA and Google Prediction API. Different approaches were followed for each tool to determine the polarity of each response (i.e. positive, negative or neutral). Overall, the non-commercial tools outperformed their commercial counterparts. However, due to the different features offered by the tools, specific recommendations are made for each. In addition, single-sentence responses were tested in isolation to determine the extent to which they more clearly express a single polarity. Further work can be done to establish the relationship between single-sentence responses and the sentiment they express.},
author = {Georgiou, Despo and MacFarlane, Andrew and Russell-Rose, Tony},
doi = {10.1109/SAI.2015.7237168},
file = {:Users/ccrowe/Downloads/Extracting_sentiment_from_healthcare_survey_data_An_evaluation_of_sentiment_analysis_tools.pdf:pdf},
isbn = {9781479985470},
journal = {Proceedings of the 2015 Science and Information Conference, SAI 2015},
keywords = {classification,healthcare,machine learning,sentiment analysis,tools},
pages = {352--361},
publisher = {IEEE},
title = {{Extracting sentiment from healthcare survey data: An evaluation of sentiment analysis tools}},
year = {2015}
}
@INPROCEEDINGS{8029313,
  author={Straton, Nadiya and Mukkamala, Raghava Rao and Vatrapu, Ravi},
  booktitle={2017 IEEE International Congress on Big Data (BigData Congress)}, 
  title={Big Social Data Analytics for Public Health: Predicting Facebook Post Performance Using Artificial Neural Networks and Deep Learning}, 
  year={2017},
  volume={},
  number={},
  pages={89-96},
  doi={10.1109/BigDataCongress.2017.21}}

@article{Ohsawa2013,
abstract = {Recent growth of social media has produced a new market for branding of people and businesses. Facebook provides Facebook Pages (Pages in short) for public figures and businesses (we call entities) to communicate with their fans through a Like button. Because Like counts sometimes reflect the popularity of entities, techniques to increase the Like count can be a matter of interest, and might be known as social media marketing. From an academic perspective, Like counts of Pages depend not only on the popularity of the entity, but also on the popularity of semantically related entities. For example, Lady Gaga's Page has many Likes; her song "Poker Face" does too. We can infer that her next song will acquire many Likes immediately. Important questions are these: How does the Like count of Lady Gaga affect the Like count of her song? Alternatively, how does the Like count of her song constitute some fraction of the Like count of Lady Gaga herself? As described in this paper, we strive to reveal the mutual influences of Like counts among semantically related entities. To measure the influence of related entities, we propose a problem called the Like prediction problem (LPP). It models Like counts of a given entity using information of related entities. The semantic relations among entities, expressed as RDF predicates, are obtained by linking each Page with the most similar DBpedia entity. Using the model learned by support vector regression (SVR) on LPP, we can estimate the Like count of a new entity e.g., Lady Gaga's new song. More importantly, we can analyze which RDF predicates are important to infer Like counts, providing a mutual influence network among entities. Our study comprises three parts: (1) crawling the Pages and their Like counts, (2) linking Pages to DBpedia, and (3) constructing features to solve the LPP. Our study, based on 20 million Pages with 30 billion Likes, is the largest-scale study of Facebook Likes ever reported. This research constitutes a new attempt to integrate unstructured emotional data such as Likes, with Linked data, and to provide new insights for branding with social media.},
author = {Ohsawa, Shohei and Matsuo, Yutaka},
doi = {10.1145/2487788.2487992},
isbn = {978-1-4503-2038-2},
journal = {Proceedings of the 22Nd International Conference on World Wide Web Companion},
keywords = {entity linking,facebook,feature construction,link-based prediction,linked data},
pages = {541--548},
title = {{Like Prediction: Modeling Like Counts by Bridging Facebook Pages with Linked Data}},
url = {http://dl.acm.org/citation.cfm?id=2487788.2487992},
year = {2013}
}

@article{Li2015,
abstract = {We present the problem of click-through prediction for advertis-ing in Twitter timeline, which displays a stream of Tweets from accounts a user choose to follow. Traditional computational adver-tising usually appears in two forms: sponsored search that places ads onto the search result page when a query is issued to a search engine, and contextual advertising that places ads onto a regular, usually static Web page. Compared with these two paradigms, placing ads into a Tweet stream is particularly challenging given the nature of the data stream: the context into which an ad can be placed updates dynamically and never replicates. Every ad is therefore placed into a unique context. This makes the information available for training a machine learning model extremely sparse. In this study, we propose a learning-to-rank method which not only addresses the sparsity of training signals but also can be trained and updated online. The proposed method is evaluated using both offline experiments and online A/B tests, which involve very large collections of Twitter data and real Twitter users. Results of the experiments prove the effectiveness and efficiency of our solution, and its superiority over the current production model adopted by Twitter.},
author = {Li, Cheng and Lu, Yue and Mei, Qiaozhu and Wang, Dong and Pandey, Sandeep},
doi = {10.1145/2783258.2788582},
isbn = {9781450336642},
journal = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD '15},
keywords = {click-through predic-,online advertising,social media stream},
pages = {1959--1968},
title = {{Click-through Prediction for Advertising in Twitter Timeline}},
url = {http://dl.acm.org/citation.cfm?doid=2783258.2788582},
year = {2015}
}

@article{Wang2015,
abstract = {Recently text-based sentiment prediction has been extensively studied, while image-centric sentiment analysis receives much less attention. In this pa-per, we study the problem of understanding human sentiments from large-scale social media images, considering both visual content and contextual in-formation, such as comments on the images, cap-tions, etc. The challenge of this problem lies in the " semantic gap " between low-level visual fea-tures and higher-level image sentiments. Moreover, the lack of proper annotations/labels in the major-ity of social media images presents another chal-lenge. To address these two challenges, we propose a novel Unsupervised SEntiment Analysis (USEA) framework for social media images. Our approach exploits relations among visual content and rele-vant contextual information to bridge the " semantic gap " in the prediction of image sentiments. With experiments on two large-scale datasets, we show that the proposed method is effective in addressing the two challenges.},
author = {Wang, Yilin and Wang, Suhang and Tang, Jiliang and Liu, Huan and Li, Baoxin},
isbn = {9781577357384},
journal = {Proceedings of the 24th International Conference on Artificial Intelligence},
pages = {2378--2379},
title = {{Unsupervised sentiment analysis for social media images}},
url = {https://arxiv.org/abs/1604.03489},
year = {2015}
}

@article{Liu2012,
abstract = {http://www.morganclaypool.com/doi/abs/10.2200/S00416ED1V01Y201204HLT016},
archivePrefix = {arXiv},
arxivId = {1003.5699},
author = {Liu, Bing},
doi = {10.2200/S00416ED1V01Y201204HLT016},
eprint = {1003.5699},
isbn = {9781608458844},
issn = {1947-4040},
number = {May},
pages = {1--108},
pmid = {791643259},
title = {{Sentiment Analysis and Opinion Mining}},
year = {2012}
}
  

@article{Chen2014,
abstract = {This paper introduces a visual sentiment concept classification method based on deep convolutional neural networks (CNNs). The visual sentiment concepts are adjective noun pairs (ANPs) automatically discovered from the tags of web photos, and can be utilized as effective statistical cues for detecting emotions depicted in the images. Nearly one million Flickr images tagged with these ANPs are downloaded to train the classifiers of the concepts. We adopt the popular model of deep convolutional neural networks which recently shows great performance improvement on classifying large-scale web-based image dataset such as ImageNet. Our deep CNNs model is trained based on Caffe, a newly developed deep learning framework. To deal with the biased training data which only contains images with strong sentiment and to prevent overfitting, we initialize the model with the model weights trained from ImageNet. Performance evaluation shows the newly trained deep CNNs model SentiBank 2.0 (or called DeepSentiBank) is significantly improved in both annotation accuracy and retrieval performance, compared to its predecessors which mainly use binary SVM classification models.},
archivePrefix = {arXiv},
arxivId = {1410.8586},
author = {Chen, Tao and Borth, Damian and Darrell, Trevor and Chang, Shih-Fu},
eprint = {1410.8586},
file = {:Users/ccrowe/Library/Application Support/Mendeley Desktop/Downloaded/Chen et al. - 2014 - DeepSentiBank Visual Sentiment Concept Classification with Deep Convolutional Neural Networks.pdf:pdf},
isbn = {9781509040452},
keywords = {affective computing,deep learning,visual sentiment},
title = {{DeepSentiBank: Visual Sentiment Concept Classification with Deep Convolutional Neural Networks}},
url = {http://arxiv.org/abs/1410.8586},
year = {2014}
}
    
@article{Poria2016,
abstract = {Sarcasm detection is a key task for many natural language processing tasks. In sentiment analysis, for example, sarcasm can flip the polarity of an "apparently positive" sentence and, hence, negatively affect polarity detection performance. To date, most approaches to sarcasm detection have treated the task primarily as a text categorization problem. Sarcasm, however, can be expressed in very subtle ways and requires a deeper understanding of natural language that standard text categorization techniques cannot grasp. In this work, we develop models based on a pre-trained convolutional neural network for extracting sentiment, emotion and personality features for sarcasm detection. Such features, along with the network's baseline features, allow the proposed models to outperform the state of the art on benchmark datasets. We also address the often ignored generalizability issue of classifying data that have not been seen by the models at learning phase.},
archivePrefix = {arXiv},
arxivId = {1610.08815},
author = {Poria, Soujanya and Cambria, Erik and Hazarika, Devamanyu and Vij, Prateek},
eprint = {1610.08815},
file = {:Users/ccrowe/Library/Application Support/Mendeley Desktop/Downloaded/Poria et al. - 2016 - A Deeper Look into Sarcastic Tweets Using Deep Convolutional Neural Networks.pdf:pdf},
title = {{A Deeper Look into Sarcastic Tweets Using Deep Convolutional Neural Networks}},
url = {http://arxiv.org/abs/1610.08815},
year = {2016}
}
    
@article{Segalin2017,
abstract = {The role of images in the last ten years has changed radically due to the advent of social networks: from media objects mainly used to communicate visual information, images have become personal, associated with the people that create or interact with them (for example, giving a “like”). Therefore, in the same way that a post reveals something of its author, so now the images associated to a person may embed some of her individual characteristics, such as her personality traits. In this paper, we explore this new level of image understanding with the ultimate goal of relating a set of image preferences to personality traits by using a deep learning framework. In particular, our problem focuses on inferring both self-assessed (how the personality traits of a person can be guessed from her preferred image) and attributed traits (what impressions in terms of personality traits these images trigger in unacquainted people), learning a sort of wisdom of the crowds. Our characterization of each image is locked within the layers of a CNN, allowing us to discover more entangled attributes (aesthetic patterns and semantic information) and to better generalize the patterns that identify a trait. The experimental results show that the proposed method outperforms state-of-the-art results and captures what visually characterizes a certain trait: using a deconvolution strategy we found a clear distinction of features, patterns and content between low and high values in a given trait.},
author = {Segalin, Cristina and Cheng, Dong Seon and Cristani, Marco},
doi = {10.1016/J.CVIU.2016.10.013},
issn = {1077-3142},
journal = {Computer Vision and Image Understanding},
month = {mar},
pages = {34--50},
publisher = {Academic Press},
title = {{Social profiling through image understanding: Personality inference using convolutional neural networks}},
url = {https://www.sciencedirect.com/science/article/pii/S1077314216301679},
volume = {156},
year = {2017}
}
@article{Gelli2015,
abstract = {{\textcopyright} 2015 ACM.Images in social networks share difierent destinies: some are going to become popular while others are going to be com-pletely unnoticed. In this paper we propose to use visual sentiment features together with three novel context fea-tures to predict a concise popularity score of social images. Experiments on large scale datasets show the benefits of proposed features on the performance of image popularity prediction. Exploiting state-of-The-Art sentiment features, we report a qualitative analysis of which sentiments seem to be related to good or poor popularity. To the best of our knowledge, this is the first work understanding specific visual sentiments that positively or negatively inuence the eventual popularity of images.},
author = {Gelli, Francesco and Uricchio, Tiberio and Bertini, Marco and {Del Bimbo}, Alberto and Chang, Shih-Fu},
doi = {10.1145/2733373.2806361},
file = {:Users/ccrowe/Library/Application Support/Mendeley Desktop/Downloaded/Gelli et al. - 2015 - Image Popularity Prediction in Social Media Using Sentiment and Context Features.pdf:pdf},
isbn = {9781450334594},
journal = {Proceedings of the 23rd ACM international conference on Multimedia - MM '15},
keywords = {affec-,image popularity,social networks,visual sentiment},
pages = {907--910},
title = {{Image Popularity Prediction in Social Media Using Sentiment and Context Features}},
url = {http://dl.acm.org/citation.cfm?doid=2733373.2806361},
year = {2015}
}
@article{Hassner2015,
abstract = {A key point in automatic age estimation is to design feature set essential to age perception. To achieve this goal, this paper builds up a hierarchical graphical face model for faces appearing at low, middle and high resolution respectively. Along the hierarchy, a face image is decomposed into detailed parts from coarse to fine. Then four types of features are extracted from this graph representation guided by the priors of aging process embedded in the graphical model: topology, geometry, photometry and configuration. On age estimation, this paper follows the popular regression formulation for mapping feature vectors to its age label. The effectiveness of the presented feature set is justified by testing results on two datasets using different kinds of regression methods. The experimental results in this paper show that designing feature set for age estimation under the guidance of hierarchical face model is a promising method and a flexible framework as well.},
author = {Hassner, Gil Levi and Tal},
doi = {10.1109/AFGR.2008.4813314},
file = {:Users/ccrowe/Library/Application Support/Mendeley Desktop/Downloaded/Hassner - 2015 - Age and Gender Classification using Convolutional Neural Networks.pdf:pdf},
isbn = {9781424421541},
issn = {01628828},
journal = {2008 8th IEEE International Conference on Automatic Face and Gesture Recognition, FG 2008},
keywords = {Age estimation,Age manifold,Aging,Aging variation,Algorithms,Artificial Intelligence,Automated,Automated: methods,Biological,Biometry,Biometry: methods,Computer Simulation,Computer vision,Computer-Assisted,Computer-Assisted: methods,Conformal embedding analysis,Crowd density estimation,Cumulative attributes,Dimensionality reduction,Distance metric learning,Face,Face aging,Face and gesture recognition,Face recognition,Face: anatomy & histology,Human age estimation,Humans,Image Enhancement,Image Enhancement: methods,Image Interpretation,Image classification,Local regression,Locally adjusted robust regression,Machine learning,Manifold,Manifold learning,Models,Multiple linear regression,Neural networks,Nonlinear regression,Ordinal ranking,Pattern Recognition,Pattern recognition,Reproducibility of Results,Sensitivity and Specificity,Statistical face models,Subspace learning,Support vector machine (SVM),Support vector regression (SVR),active appearance model,age estimation,age progression,age specific human-computer interaction,age synthesis,aging pattern,all or part of,automatic age,binary classification,estimation,face image,face recognition,facial image processing,human age estimation,label distribution,machine learning,or hard copies of,permission to make digital,ranking,scattering transform,survey,this work for},
number = {3},
pages = {2622--2629},
pmid = {25576566},
title = {{Age and Gender Classification using Convolutional Neural Networks}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4761364%5Cnhttp://portal.acm.org/citation.cfm?doid=1180639.1180711%5Cnhttp://www.ncbi.nlm.nih.gov/pubmed/21193381%5Cnhttp://dx.doi.org/10.1016/j.patcog.2012.09.011},
volume = {24},
year = {2015}
}
  
@article{TIAGO2014703,
title = {Digital marketing and social media: Why bother?},
journal = {Business Horizons},
volume = {57},
number = {6},
pages = {703-708},
year = {2014},
note = {SPECIAL ISSUE: INBAM},
issn = {0007-6813},
doi = {https://doi.org/10.1016/j.bushor.2014.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S0007681314000949},
author = {Maria Teresa Pinheiro Melo Borges Tiago and José Manuel Cristóvão Veríssimo},
keywords = {Digital marketing, Budget spending, Social metrics, Digital media trends},
abstract = {Changes in consumer behavior require firms to rethink their marketing strategies in the digital domain. Currently, a significant portion of the associated research is focused more on the customer than on the firm. To redress this shortcoming, this study adopts the perspective of the firm to facilitate an understanding of digital marketing and social media usage as well as its benefits and inhibitors. The second generation of Internet-based applications enhances marketing efforts by allowing firms to implement innovative forms of communication and co-create content with their customers. Based on a survey of marketing managers, this article shows that firms face internal and external pressures to adopt a digital presence in social media platforms. Firms’ digital marketing engagement can be categorized according to perceived benefits and digital marketing usage. To improve digital marketing engagement, marketers must focus on relationship-based interactions with their customers. This article demonstrates how some firms are already accomplishing just that.}
}  
@article{Fisher2009,
abstract = {Return on Investment (ROI) has become the Holy Grail of social media. Marketers are being squeezed between admonishments to participate in the vast new online communications available to them and demands to justify the cost using conventional advertising metrics. New ROI calculators are being created almost as fast as new social networking sites- then just as quickly being dismissed as being unworkable. In this article, Tia Fisher of eModeration takes a long view of the current state of ROI in social media, and examines the arguments for and against attempting to use any kind of metric to justify involvement in a social media program. {\textcopyright} 2009 Palgrave Macmillan.},
author = {Fisher, Tia},
doi = {10.1057/dbm.2009.16},
file = {:Users/ccrowe/Library/Application Support/Mendeley Desktop/Downloaded/Fisher - 2009 - ROI in social media A look at the arguments.pdf:pdf},
issn = {17412439},
journal = {Journal of Database Marketing and Customer Strategy Management},
keywords = {Marketing,Marketing budgets,ROI,Social media},
number = {3},
pages = {189--195},
title = {{ROI in social media: A look at the arguments}},
volume = {16},
year = {2009}
}
  
@article{Romero2011,
abstract = {Purpose: In all projections for 2011, ROI has become of the great challenges of social media marketing for the business environment. However in the case of non-profit organizations, there is no need for such calculations. It is not as necessary to know how the effort made in these media compares to the benefits that can be obtained. This paper aims to compare the parameters governing social media ROI at an enterprise level and at the level of non-profit institutions. Additionally, the use of social media tools in a strategic plan and to save costs in the institution is discussed. Design/methodology/approach: Where ROI is defined as a mere indicator of return on investment, it involves the direct costs and revenues of each transaction. Combining the world of social media marketing, which is full of intangibles, with the current crisis makes knowing "real" return one of the greatest current needs. When demanding returns from institutions that have never been analyzed from this standpoint, it is important to understand how a tool like this can be used to justify an entity's visibility, brand improvement and ultimately, an increase in the institution's quality and use by users. Also, it should be taken into account that while in 2010 branding was the primary goal of communication in social media, this year in view of the increasingly endemic crisis, a ROI analysis can help an institution to evidence how the cost savings inherent in using these as opposed to former marketing tools substantiate their use. However, this interest involves a great risk of simplification. Findings: The analysis used to measure ROI can follow these lines: The consumption by previous users can be compared with that of current arrivals on the network. Comparisons can be made between the behavior of a user prior to following the library on social media and after doing so. The extent to which the success of new developments, events etc. has improved after being communicated in social networks can be measured. The influence of brand perception on users' consumption and the extent to which the new media have changed this perception can be measured. Originality/value: Conducting a ROI analysis of a library's social media marketing campaign can help it evaluate various aspects in the library. Social media can be considered as an interesting information dissemination tool requiring only minimal effort which can be used by the library to promote reading and publicize its informational and cultural efforts. Social media can also be used as dynamic, provision of service and marketing resources with a clear reduction in costs compared to other more traditional types of advertising and publicizing. Given that in the management of these tools, it is the contents and ideas that are essential rather than the economic resources available, social media are particularly useful for small and medium libraries as they provide the possibility of increasing the visibility of the institution and improving its service and its users' experience. Opening a new channel of communication with users on the internet is a challenge for libraries that can be optimized with the development of a strategy for the use of social media. The library should make an effort to manage these resources efficiently and obtain the largest possible return on their use. {\textcopyright} Emerald Group Publishing Limited.},
author = {Romero, Nuria Lloret},
doi = {10.1108/08880451111169223},
issn = {0888045X},
journal = {Bottom Line},
number = {2},
title = {{ROI. Measuring the social media return on investment in a library}},
volume = {24},
year = {2011}
}
  
@article{Schacht2015,
abstract = {Large numbers of today's businesses use social media in advertising. There is a belief in a great opportunity, even if return on investment is difficult to quantify. To fill this gap we consider a cross-media-platform-analysis across Facebook, Twitter and Foursquare. Rationale for and against different characteristics within social media advertisement are addressed. The paper finds correlation from posts and tweets to Foursquare check-ins. Results show that posts or tweets containing pictures have higher return on investment than posts or tweets without, and that when the text of a post or tweet raises curiosity or attracts individuals or groups Foursquare check-ins increase.},
author = {Schacht, Johanna and Hall, Margeret and Chorley, Martin},
doi = {10.1145/2786451.2786923},
file = {:Users/ccrowe/Library/Application Support/Mendeley Desktop/Downloaded/Schacht, Hall, Chorley - 2015 - Tweet if you will - The real question is, who do you influence.pdf:pdf},
isbn = {9781450336727},
journal = {Proceedings of the 2015 ACM Web Science Conference},
number = {June},
title = {{Tweet if you will - The real question is, who do you influence?}},
year = {2015}
}

@article{Wang2015,
abstract = {Recently text-based sentiment prediction has been extensively studied, while image-centric sentiment analysis receives much less attention. In this pa-per, we study the problem of understanding human sentiments from large-scale social media images, considering both visual content and contextual in-formation, such as comments on the images, cap-tions, etc. The challenge of this problem lies in the " semantic gap " between low-level visual fea-tures and higher-level image sentiments. Moreover, the lack of proper annotations/labels in the major-ity of social media images presents another chal-lenge. To address these two challenges, we propose a novel Unsupervised SEntiment Analysis (USEA) framework for social media images. Our approach exploits relations among visual content and rele-vant contextual information to bridge the " semantic gap " in the prediction of image sentiments. With experiments on two large-scale datasets, we show that the proposed method is effective in addressing the two challenges.},
author = {Wang, Yilin and Wang, Suhang and Tang, Jiliang and Liu, Huan and Li, Baoxin},
isbn = {9781577357384},
journal = {Proceedings of the 24th International Conference on Artificial Intelligence},
pages = {2378--2379},
title = {{Unsupervised sentiment analysis for social media images}},
url = {https://arxiv.org/abs/1604.03489},
year = {2015}
}
  
@article{Poria2016,
abstract = {Sarcasm detection is a key task for many natural language processing tasks. In sentiment analysis, for example, sarcasm can flip the polarity of an "apparently positive" sentence and, hence, negatively affect polarity detection performance. To date, most approaches to sarcasm detection have treated the task primarily as a text categorization problem. Sarcasm, however, can be expressed in very subtle ways and requires a deeper understanding of natural language that standard text categorization techniques cannot grasp. In this work, we develop models based on a pre-trained convolutional neural network for extracting sentiment, emotion and personality features for sarcasm detection. Such features, along with the network's baseline features, allow the proposed models to outperform the state of the art on benchmark datasets. We also address the often ignored generalizability issue of classifying data that have not been seen by the models at learning phase.},
archivePrefix = {arXiv},
arxivId = {1610.08815},
author = {Poria, Soujanya and Cambria, Erik and Hazarika, Devamanyu and Vij, Prateek},
eprint = {1610.08815},
file = {:Users/ccrowe/Library/Application Support/Mendeley Desktop/Downloaded/Poria et al. - 2016 - A Deeper Look into Sarcastic Tweets Using Deep Convolutional Neural Networks.pdf:pdf},
title = {{A Deeper Look into Sarcastic Tweets Using Deep Convolutional Neural Networks}},
url = {http://arxiv.org/abs/1610.08815},
year = {2016}
}
  
@article{Khosla2014,
abstract = {Hundreds of thousands of photographs are uploaded to the internet every minute through various social networking and photo sharing platforms. While some images get millions of views, others are completely ignored. Even from the same users, different photographs receive different number of views. This begs the question: What makes a photograph popular? Can we predict the number of views a photograph will receive even before it is uploaded? These are some of the questions we address in this work. We investigate two key components of an image that affect its popularity, namely the image content and social context. Using a dataset of about 2.3 million images from Flickr, we demonstrate that we can reliably predict the normalized view count of images with a rank correlation of 0.81 using both image content and social cues. In this paper, we show the importance of image cues such as color, gradients, deep learning features and the set of objects present, as well as the importance of various social cues such as number of friends or number of photos uploaded that lead to high or low popularity of images.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Khosla, Aditya and {Das Sarma}, Atish and Hamid, Raffay},
doi = {10.1145/2566486.2567996},
eprint = {arXiv:1011.1669v3},
file = {:Users/ccrowe/Library/Application Support/Mendeley Desktop/Downloaded/Khosla, Das Sarma, Hamid - 2014 - What Makes an Image Popular.pdf:pdf},
isbn = {9781450327442},
issn = {9781450327442},
journal = {Proceedings of the 23rd International Conference on World Wide Web},
keywords = {deep learning,flickr,images,popularity,regression},
pages = {867----876},
pmid = {15003161},
title = {{What Makes an Image Popular ?}},
url = {http://dl.acm.org/citation.cfm?id=2567996},
year = {2014}
}
  
@article{Chen2014,
abstract = {This paper introduces a visual sentiment concept classification method based on deep convolutional neural networks (CNNs). The visual sentiment concepts are adjective noun pairs (ANPs) automatically discovered from the tags of web photos, and can be utilized as effective statistical cues for detecting emotions depicted in the images. Nearly one million Flickr images tagged with these ANPs are downloaded to train the classifiers of the concepts. We adopt the popular model of deep convolutional neural networks which recently shows great performance improvement on classifying large-scale web-based image dataset such as ImageNet. Our deep CNNs model is trained based on Caffe, a newly developed deep learning framework. To deal with the biased training data which only contains images with strong sentiment and to prevent overfitting, we initialize the model with the model weights trained from ImageNet. Performance evaluation shows the newly trained deep CNNs model SentiBank 2.0 (or called DeepSentiBank) is significantly improved in both annotation accuracy and retrieval performance, compared to its predecessors which mainly use binary SVM classification models.},
archivePrefix = {arXiv},
arxivId = {1410.8586},
author = {Chen, Tao and Borth, Damian and Darrell, Trevor and Chang, Shih-Fu},
eprint = {1410.8586},
file = {:Users/ccrowe/Library/Application Support/Mendeley Desktop/Downloaded/Chen et al. - 2014 - DeepSentiBank Visual Sentiment Concept Classification with Deep Convolutional Neural Networks.pdf:pdf},
isbn = {9781509040452},
keywords = {affective computing,deep learning,visual sentiment},
title = {{DeepSentiBank: Visual Sentiment Concept Classification with Deep Convolutional Neural Networks}},
url = {http://arxiv.org/abs/1410.8586},
year = {2014}
}
  
@article{Segalin2017,
abstract = {The role of images in the last ten years has changed radically due to the advent of social networks: from media objects mainly used to communicate visual information, images have become personal, associated with the people that create or interact with them (for example, giving a “like”). Therefore, in the same way that a post reveals something of its author, so now the images associated to a person may embed some of her individual characteristics, such as her personality traits. In this paper, we explore this new level of image understanding with the ultimate goal of relating a set of image preferences to personality traits by using a deep learning framework. In particular, our problem focuses on inferring both self-assessed (how the personality traits of a person can be guessed from her preferred image) and attributed traits (what impressions in terms of personality traits these images trigger in unacquainted people), learning a sort of wisdom of the crowds. Our characterization of each image is locked within the layers of a CNN, allowing us to discover more entangled attributes (aesthetic patterns and semantic information) and to better generalize the patterns that identify a trait. The experimental results show that the proposed method outperforms state-of-the-art results and captures what visually characterizes a certain trait: using a deconvolution strategy we found a clear distinction of features, patterns and content between low and high values in a given trait.},
author = {Segalin, Cristina and Cheng, Dong Seon and Cristani, Marco},
doi = {10.1016/J.CVIU.2016.10.013},
issn = {1077-3142},
journal = {Computer Vision and Image Understanding},
month = {mar},
pages = {34--50},
publisher = {Academic Press},
title = {{Social profiling through image understanding: Personality inference using convolutional neural networks}},
url = {https://www.sciencedirect.com/science/article/pii/S1077314216301679},
volume = {156},
year = {2017}
}
  
@article{Lin2014,
abstract = {It is of significant importance to detect and manage stress before it turns into severe problems. However, existing stress detection methods usually rely on psychological scales or physiological devices, making the detection complicated and costly. In this paper, we explore to automatically detect individuals' psychological stress via social media. Employing real online micro-blog data, we first investigate the correlations between users' stress and their tweeting content, social engagement and behavior patterns. Then we define two types of stress-related attributes: 1) low-level content attributes from a single tweet, including text, images and social interactions; 2) user-scope statistical attributes through their weekly micro-blog postings, leveraging information of tweeting time, tweeting types and linguistic styles. To combine content attributes with statistical attributes, we further design a convolutional neural network (CNN) with cross autoencoders to generate user-scope content attributes from low-level content attributes. Finally, we propose a deep neural network (DNN) model to incorporate the two types of user-scope attributes to detect users' psychological stress. We test the trained model on four different datasets from major micro-blog platforms including Sina Weibo, Tencent Weibo and Twitter. Experimental results show that the proposed model is effective and efficient on detecting psychological stress from micro-blog data. We believe our model would be useful in developing stress detection tools for mental health agencies and individuals.},
author = {Lin, Huijie and Jia, Jia and Guo, Quan and Xue, Yuanyuan and Li, Qi and Huang, Jie and Cai, Lianhong and Feng, Ling},
doi = {10.1145/2647868.2654945},
file = {:Users/ccrowe/Library/Application Support/Mendeley Desktop/Downloaded/Lin et al. - 2014 - User-level psychological stress detection from social media using deep neural network.pdf:pdf},
isbn = {9781450330633},
journal = {Proceedings of the ACM International Conference on Multimedia - MM '14},
pages = {507--516},
title = {{User-level psychological stress detection from social media using deep neural network}},
url = {http://dl.acm.org/citation.cfm?doid=2647868.2654945},
year = {2014}
}
  
@article{Xu2014,
abstract = {Images have become one of the most popular types of media through which users convey their emotions within online social networks. Although vast amount of research is devoted to sentiment analysis of textual data, there has been very limited work that focuses on analyzing sentiment of image data. In this work, we propose a novel visual sentiment prediction framework that performs image understanding with Deep Convolutional Neural Networks (CNN). Specifically, the proposed sentiment prediction framework performs transfer learning from a CNN with millions of parameters, which is pre-trained on large-scale data for object recognition. Experiments conducted on two real-world datasets from Twitter and Tumblr demonstrate the effectiveness of the proposed visual sentiment analysis framework.},
archivePrefix = {arXiv},
arxivId = {1411.5731},
author = {Xu, Can and Cetintas, Suleyman and Lee, Kuang-Chih and Li, Li-Jia},
eprint = {1411.5731},
file = {:Users/ccrowe/Library/Application Support/Mendeley Desktop/Downloaded/Xu et al. - 2014 - Visual Sentiment Prediction with Deep Convolutional Neural Networks.pdf:pdf},
title = {{Visual Sentiment Prediction with Deep Convolutional Neural Networks}},
url = {http://arxiv.org/abs/1411.5731},
year = {2014}
}
@misc{Greenwood2016,
abstract = {Over the past decade, Pew Research Center has documented the wide variety of ways in which Americans use social media to seek out information and interact with others. A majority of Americans now say they get news via social media, and half of the public has turned to these sites to learn about the 2016 presidential election. Americans are using social media in the context of work (whether to take a mental break on the job or to seek out employment), while also engaging in an ongoing effort to navigate the complex privacy issues that these sites bring to the forefront. In addition to measuring the broad impact and meaning of social media, since 2012 the Center has also tracked the specific sites and platforms that users turn to in the course of living their social lives online. In that context, a national survey of 1,520 adults conducted March 7-April 4, 2016, finds that Facebook continues to be America's most popular social networking platform by a substantial margin: Nearly eight-in-ten online Americans 1 (79%) now use Facebook, more than double the share that uses Twitter (24%), Pinterest (31%), Instagram (32%) or LinkedIn (29%). On a total population basis (accounting for Americans who do not use the internet at all), that means that 68% of all U.S. adults are Facebook users, while 28% use Instagram, 26% use Pinterest, 25% use LinkedIn and 21% use Twitter. Thanks in part to the growing number of older adults who are joining the site, Facebook use appears to be on the rise: The share of online adults who report using Facebook has increased by 7 percentage points compared with a Pew Research Center survey conducted at a similar point in 2015. In addition, the share of Facebook users who check in daily has increased slightly in the past year: 76% of Americans who use Facebook now report that they visit the site on a daily basis, up from 70% in 2015. },
author = {Greenwood, Shannon and Perrin, Andrew and Duggan, Maeve},
booktitle = {Policy File},
keywords = {Social conditions & trends ; Pew Research Center ;},
publisher = {Pew Research Center},
title = {{Social Media Update 2016}},
year = {2016}
}
@article{Authors2013,
archivePrefix = {arXiv},
arxivId = {http://dx.doi.org/10.1108/BIJ-10-2012-0068},
author = {Authors, For},
eprint = {/dx.doi.org/10.1108/BIJ-10-2012-0068},
file = {:Users/ccrowe/Library/Application Support/Mendeley Desktop/Downloaded/Authors - 2013 - Do users look at banner ads on Facebook.pdf:pdf},
isbn = {0420170014},
issn = {0957-4093},
journal = {Journal of Research in Interactive Marketing},
number = {2},
pages = {119--139},
pmid = {42012058},
primaryClass = {http:},
title = {{Do users look at banner ads on Facebook?}},
volume = {7},
year = {2013}
}